<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - PostgreSQL 13devel - src/backend/executor/execParallel.c</title>
  <link rel="stylesheet" type="text/css" href="../../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../../index.html">top level</a> - <a href="index.html">src/backend/executor</a> - execParallel.c<span style="font-size: 80%;"> (source / <a href="execParallel.c.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">PostgreSQL 13devel</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">458</td>
            <td class="headerCovTableEntry">504</td>
            <td class="headerCovTableEntryHi">90.9 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2019-11-27 09:34:56</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">20</td>
            <td class="headerCovTableEntry">20</td>
            <td class="headerCovTableEntryHi">100.0 %</td>
          </tr>
          <tr>
            <td class="headerItem">Legend:</td>
            <td class="headerValueLeg">            Lines:
            <span class="coverLegendCov">hit</span>
            <span class="coverLegendNoCov">not hit</span>
</td>
            <td></td>
          </tr>
          <tr><td><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : /*-------------------------------------------------------------------------</a>
<span class="lineNum">       2 </span>            :  *
<span class="lineNum">       3 </span>            :  * execParallel.c
<span class="lineNum">       4 </span>            :  *    Support routines for parallel execution.
<span class="lineNum">       5 </span>            :  *
<span class="lineNum">       6 </span>            :  * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
<span class="lineNum">       7 </span>            :  * Portions Copyright (c) 1994, Regents of the University of California
<span class="lineNum">       8 </span>            :  *
<span class="lineNum">       9 </span>            :  * This file contains routines that are intended to support setting up,
<span class="lineNum">      10 </span>            :  * using, and tearing down a ParallelContext from within the PostgreSQL
<span class="lineNum">      11 </span>            :  * executor.  The ParallelContext machinery will handle starting the
<span class="lineNum">      12 </span>            :  * workers and ensuring that their state generally matches that of the
<span class="lineNum">      13 </span>            :  * leader; see src/backend/access/transam/README.parallel for details.
<span class="lineNum">      14 </span>            :  * However, we must save and restore relevant executor state, such as
<span class="lineNum">      15 </span>            :  * any ParamListInfo associated with the query, buffer usage info, and
<span class="lineNum">      16 </span>            :  * the actual plan to be passed down to the worker.
<span class="lineNum">      17 </span>            :  *
<span class="lineNum">      18 </span>            :  * IDENTIFICATION
<span class="lineNum">      19 </span>            :  *    src/backend/executor/execParallel.c
<span class="lineNum">      20 </span>            :  *
<span class="lineNum">      21 </span>            :  *-------------------------------------------------------------------------
<span class="lineNum">      22 </span>            :  */
<span class="lineNum">      23 </span>            : 
<span class="lineNum">      24 </span>            : #include &quot;postgres.h&quot;
<span class="lineNum">      25 </span>            : 
<span class="lineNum">      26 </span>            : #include &quot;executor/execParallel.h&quot;
<span class="lineNum">      27 </span>            : #include &quot;executor/executor.h&quot;
<span class="lineNum">      28 </span>            : #include &quot;executor/nodeAppend.h&quot;
<span class="lineNum">      29 </span>            : #include &quot;executor/nodeBitmapHeapscan.h&quot;
<span class="lineNum">      30 </span>            : #include &quot;executor/nodeCustom.h&quot;
<span class="lineNum">      31 </span>            : #include &quot;executor/nodeForeignscan.h&quot;
<span class="lineNum">      32 </span>            : #include &quot;executor/nodeHash.h&quot;
<span class="lineNum">      33 </span>            : #include &quot;executor/nodeHashjoin.h&quot;
<span class="lineNum">      34 </span>            : #include &quot;executor/nodeIndexonlyscan.h&quot;
<span class="lineNum">      35 </span>            : #include &quot;executor/nodeIndexscan.h&quot;
<span class="lineNum">      36 </span>            : #include &quot;executor/nodeSeqscan.h&quot;
<span class="lineNum">      37 </span>            : #include &quot;executor/nodeSort.h&quot;
<span class="lineNum">      38 </span>            : #include &quot;executor/nodeSubplan.h&quot;
<span class="lineNum">      39 </span>            : #include &quot;executor/tqueue.h&quot;
<span class="lineNum">      40 </span>            : #include &quot;jit/jit.h&quot;
<span class="lineNum">      41 </span>            : #include &quot;nodes/nodeFuncs.h&quot;
<span class="lineNum">      42 </span>            : #include &quot;pgstat.h&quot;
<span class="lineNum">      43 </span>            : #include &quot;storage/spin.h&quot;
<span class="lineNum">      44 </span>            : #include &quot;tcop/tcopprot.h&quot;
<span class="lineNum">      45 </span>            : #include &quot;utils/datum.h&quot;
<span class="lineNum">      46 </span>            : #include &quot;utils/dsa.h&quot;
<span class="lineNum">      47 </span>            : #include &quot;utils/lsyscache.h&quot;
<span class="lineNum">      48 </span>            : #include &quot;utils/memutils.h&quot;
<span class="lineNum">      49 </span>            : #include &quot;utils/snapmgr.h&quot;
<span class="lineNum">      50 </span>            : 
<span class="lineNum">      51 </span>            : /*
<span class="lineNum">      52 </span>            :  * Magic numbers for parallel executor communication.  We use constants
<span class="lineNum">      53 </span>            :  * greater than any 32-bit integer here so that values &lt; 2^32 can be used
<span class="lineNum">      54 </span>            :  * by individual parallel nodes to store their own state.
<span class="lineNum">      55 </span>            :  */
<span class="lineNum">      56 </span>            : #define PARALLEL_KEY_EXECUTOR_FIXED     UINT64CONST(0xE000000000000001)
<span class="lineNum">      57 </span>            : #define PARALLEL_KEY_PLANNEDSTMT        UINT64CONST(0xE000000000000002)
<span class="lineNum">      58 </span>            : #define PARALLEL_KEY_PARAMLISTINFO      UINT64CONST(0xE000000000000003)
<span class="lineNum">      59 </span>            : #define PARALLEL_KEY_BUFFER_USAGE       UINT64CONST(0xE000000000000004)
<span class="lineNum">      60 </span>            : #define PARALLEL_KEY_TUPLE_QUEUE        UINT64CONST(0xE000000000000005)
<span class="lineNum">      61 </span>            : #define PARALLEL_KEY_INSTRUMENTATION    UINT64CONST(0xE000000000000006)
<span class="lineNum">      62 </span>            : #define PARALLEL_KEY_DSA                UINT64CONST(0xE000000000000007)
<span class="lineNum">      63 </span>            : #define PARALLEL_KEY_QUERY_TEXT     UINT64CONST(0xE000000000000008)
<span class="lineNum">      64 </span>            : #define PARALLEL_KEY_JIT_INSTRUMENTATION UINT64CONST(0xE000000000000009)
<span class="lineNum">      65 </span>            : 
<span class="lineNum">      66 </span>            : #define PARALLEL_TUPLE_QUEUE_SIZE       65536
<span class="lineNum">      67 </span>            : 
<span class="lineNum">      68 </span>            : /*
<span class="lineNum">      69 </span>            :  * Fixed-size random stuff that we need to pass to parallel workers.
<span class="lineNum">      70 </span>            :  */
<span class="lineNum">      71 </span>            : typedef struct FixedParallelExecutorState
<span class="lineNum">      72 </span>            : {
<span class="lineNum">      73 </span>            :     int64       tuples_needed;  /* tuple bound, see ExecSetTupleBound */
<span class="lineNum">      74 </span>            :     dsa_pointer param_exec;
<span class="lineNum">      75 </span>            :     int         eflags;
<span class="lineNum">      76 </span>            :     int         jit_flags;
<span class="lineNum">      77 </span>            : } FixedParallelExecutorState;
<span class="lineNum">      78 </span>            : 
<span class="lineNum">      79 </span>            : /*
<span class="lineNum">      80 </span>            :  * DSM structure for accumulating per-PlanState instrumentation.
<span class="lineNum">      81 </span>            :  *
<span class="lineNum">      82 </span>            :  * instrument_options: Same meaning here as in instrument.c.
<span class="lineNum">      83 </span>            :  *
<span class="lineNum">      84 </span>            :  * instrument_offset: Offset, relative to the start of this structure,
<span class="lineNum">      85 </span>            :  * of the first Instrumentation object.  This will depend on the length of
<span class="lineNum">      86 </span>            :  * the plan_node_id array.
<span class="lineNum">      87 </span>            :  *
<span class="lineNum">      88 </span>            :  * num_workers: Number of workers.
<span class="lineNum">      89 </span>            :  *
<span class="lineNum">      90 </span>            :  * num_plan_nodes: Number of plan nodes.
<span class="lineNum">      91 </span>            :  *
<span class="lineNum">      92 </span>            :  * plan_node_id: Array of plan nodes for which we are gathering instrumentation
<span class="lineNum">      93 </span>            :  * from parallel workers.  The length of this array is given by num_plan_nodes.
<span class="lineNum">      94 </span>            :  */
<span class="lineNum">      95 </span>            : struct SharedExecutorInstrumentation
<span class="lineNum">      96 </span>            : {
<span class="lineNum">      97 </span>            :     int         instrument_options;
<span class="lineNum">      98 </span>            :     int         instrument_offset;
<span class="lineNum">      99 </span>            :     int         num_workers;
<span class="lineNum">     100 </span>            :     int         num_plan_nodes;
<span class="lineNum">     101 </span>            :     int         plan_node_id[FLEXIBLE_ARRAY_MEMBER];
<span class="lineNum">     102 </span>            :     /* array of num_plan_nodes * num_workers Instrumentation objects follows */
<span class="lineNum">     103 </span>            : };
<span class="lineNum">     104 </span>            : #define GetInstrumentationArray(sei) \
<span class="lineNum">     105 </span>            :     (AssertVariableIsOfTypeMacro(sei, SharedExecutorInstrumentation *), \
<span class="lineNum">     106 </span>            :      (Instrumentation *) (((char *) sei) + sei-&gt;instrument_offset))
<span class="lineNum">     107 </span>            : 
<span class="lineNum">     108 </span>            : /* Context object for ExecParallelEstimate. */
<span class="lineNum">     109 </span>            : typedef struct ExecParallelEstimateContext
<span class="lineNum">     110 </span>            : {
<span class="lineNum">     111 </span>            :     ParallelContext *pcxt;
<span class="lineNum">     112 </span>            :     int         nnodes;
<span class="lineNum">     113 </span>            : } ExecParallelEstimateContext;
<span class="lineNum">     114 </span>            : 
<span class="lineNum">     115 </span>            : /* Context object for ExecParallelInitializeDSM. */
<span class="lineNum">     116 </span>            : typedef struct ExecParallelInitializeDSMContext
<span class="lineNum">     117 </span>            : {
<span class="lineNum">     118 </span>            :     ParallelContext *pcxt;
<span class="lineNum">     119 </span>            :     SharedExecutorInstrumentation *instrumentation;
<span class="lineNum">     120 </span>            :     int         nnodes;
<span class="lineNum">     121 </span>            : } ExecParallelInitializeDSMContext;
<span class="lineNum">     122 </span>            : 
<span class="lineNum">     123 </span>            : /* Helper functions that run in the parallel leader. */
<span class="lineNum">     124 </span>            : static char *ExecSerializePlan(Plan *plan, EState *estate);
<span class="lineNum">     125 </span>            : static bool ExecParallelEstimate(PlanState *node,
<span class="lineNum">     126 </span>            :                                  ExecParallelEstimateContext *e);
<span class="lineNum">     127 </span>            : static bool ExecParallelInitializeDSM(PlanState *node,
<span class="lineNum">     128 </span>            :                                       ExecParallelInitializeDSMContext *d);
<span class="lineNum">     129 </span>            : static shm_mq_handle **ExecParallelSetupTupleQueues(ParallelContext *pcxt,
<span class="lineNum">     130 </span>            :                                                     bool reinitialize);
<span class="lineNum">     131 </span>            : static bool ExecParallelReInitializeDSM(PlanState *planstate,
<span class="lineNum">     132 </span>            :                                         ParallelContext *pcxt);
<span class="lineNum">     133 </span>            : static bool ExecParallelRetrieveInstrumentation(PlanState *planstate,
<span class="lineNum">     134 </span>            :                                                 SharedExecutorInstrumentation *instrumentation);
<span class="lineNum">     135 </span>            : 
<span class="lineNum">     136 </span>            : /* Helper function that runs in the parallel worker. */
<span class="lineNum">     137 </span>            : static DestReceiver *ExecParallelGetReceiver(dsm_segment *seg, shm_toc *toc);
<span class="lineNum">     138 </span>            : 
<span class="lineNum">     139 </span>            : /*
<span class="lineNum">     140 </span>            :  * Create a serialized representation of the plan to be sent to each worker.
<a name="141"><span class="lineNum">     141 </span>            :  */</a>
<span class="lineNum">     142 </span>            : static char *
<span class="lineNum">     143 </span><span class="lineCov">        174 : ExecSerializePlan(Plan *plan, EState *estate)</span>
<span class="lineNum">     144 </span>            : {
<span class="lineNum">     145 </span>            :     PlannedStmt *pstmt;
<span class="lineNum">     146 </span>            :     ListCell   *lc;
<span class="lineNum">     147 </span>            : 
<span class="lineNum">     148 </span>            :     /* We can't scribble on the original plan, so make a copy. */
<span class="lineNum">     149 </span><span class="lineCov">        174 :     plan = copyObject(plan);</span>
<span class="lineNum">     150 </span>            : 
<span class="lineNum">     151 </span>            :     /*
<span class="lineNum">     152 </span>            :      * The worker will start its own copy of the executor, and that copy will
<span class="lineNum">     153 </span>            :      * insert a junk filter if the toplevel node has any resjunk entries. We
<span class="lineNum">     154 </span>            :      * don't want that to happen, because while resjunk columns shouldn't be
<span class="lineNum">     155 </span>            :      * sent back to the user, here the tuples are coming back to another
<span class="lineNum">     156 </span>            :      * backend which may very well need them.  So mutate the target list
<span class="lineNum">     157 </span>            :      * accordingly.  This is sort of a hack; there might be better ways to do
<span class="lineNum">     158 </span>            :      * this...
<span class="lineNum">     159 </span>            :      */
<span class="lineNum">     160 </span><span class="lineCov">        460 :     foreach(lc, plan-&gt;targetlist)</span>
<span class="lineNum">     161 </span>            :     {
<span class="lineNum">     162 </span><span class="lineCov">        286 :         TargetEntry *tle = lfirst_node(TargetEntry, lc);</span>
<span class="lineNum">     163 </span>            : 
<span class="lineNum">     164 </span><span class="lineCov">        286 :         tle-&gt;resjunk = false;</span>
<span class="lineNum">     165 </span>            :     }
<span class="lineNum">     166 </span>            : 
<span class="lineNum">     167 </span>            :     /*
<span class="lineNum">     168 </span>            :      * Create a dummy PlannedStmt.  Most of the fields don't need to be valid
<span class="lineNum">     169 </span>            :      * for our purposes, but the worker will need at least a minimal
<span class="lineNum">     170 </span>            :      * PlannedStmt to start the executor.
<span class="lineNum">     171 </span>            :      */
<span class="lineNum">     172 </span><span class="lineCov">        174 :     pstmt = makeNode(PlannedStmt);</span>
<span class="lineNum">     173 </span><span class="lineCov">        174 :     pstmt-&gt;commandType = CMD_SELECT;</span>
<span class="lineNum">     174 </span><span class="lineCov">        174 :     pstmt-&gt;queryId = UINT64CONST(0);</span>
<span class="lineNum">     175 </span><span class="lineCov">        174 :     pstmt-&gt;hasReturning = false;</span>
<span class="lineNum">     176 </span><span class="lineCov">        174 :     pstmt-&gt;hasModifyingCTE = false;</span>
<span class="lineNum">     177 </span><span class="lineCov">        174 :     pstmt-&gt;canSetTag = true;</span>
<span class="lineNum">     178 </span><span class="lineCov">        174 :     pstmt-&gt;transientPlan = false;</span>
<span class="lineNum">     179 </span><span class="lineCov">        174 :     pstmt-&gt;dependsOnRole = false;</span>
<span class="lineNum">     180 </span><span class="lineCov">        174 :     pstmt-&gt;parallelModeNeeded = false;</span>
<span class="lineNum">     181 </span><span class="lineCov">        174 :     pstmt-&gt;planTree = plan;</span>
<span class="lineNum">     182 </span><span class="lineCov">        174 :     pstmt-&gt;rtable = estate-&gt;es_range_table;</span>
<span class="lineNum">     183 </span><span class="lineCov">        174 :     pstmt-&gt;resultRelations = NIL;</span>
<span class="lineNum">     184 </span>            : 
<span class="lineNum">     185 </span>            :     /*
<span class="lineNum">     186 </span>            :      * Transfer only parallel-safe subplans, leaving a NULL &quot;hole&quot; in the list
<span class="lineNum">     187 </span>            :      * for unsafe ones (so that the list indexes of the safe ones are
<span class="lineNum">     188 </span>            :      * preserved).  This positively ensures that the worker won't try to run,
<span class="lineNum">     189 </span>            :      * or even do ExecInitNode on, an unsafe subplan.  That's important to
<span class="lineNum">     190 </span>            :      * protect, eg, non-parallel-aware FDWs from getting into trouble.
<span class="lineNum">     191 </span>            :      */
<span class="lineNum">     192 </span><span class="lineCov">        174 :     pstmt-&gt;subplans = NIL;</span>
<span class="lineNum">     193 </span><span class="lineCov">        184 :     foreach(lc, estate-&gt;es_plannedstmt-&gt;subplans)</span>
<span class="lineNum">     194 </span>            :     {
<span class="lineNum">     195 </span><span class="lineCov">         10 :         Plan       *subplan = (Plan *) lfirst(lc);</span>
<span class="lineNum">     196 </span>            : 
<span class="lineNum">     197 </span><span class="lineCov">         10 :         if (subplan &amp;&amp; !subplan-&gt;parallel_safe)</span>
<span class="lineNum">     198 </span><span class="lineCov">          8 :             subplan = NULL;</span>
<span class="lineNum">     199 </span><span class="lineCov">         10 :         pstmt-&gt;subplans = lappend(pstmt-&gt;subplans, subplan);</span>
<span class="lineNum">     200 </span>            :     }
<span class="lineNum">     201 </span>            : 
<span class="lineNum">     202 </span><span class="lineCov">        174 :     pstmt-&gt;rewindPlanIDs = NULL;</span>
<span class="lineNum">     203 </span><span class="lineCov">        174 :     pstmt-&gt;rowMarks = NIL;</span>
<span class="lineNum">     204 </span><span class="lineCov">        174 :     pstmt-&gt;relationOids = NIL;</span>
<span class="lineNum">     205 </span><span class="lineCov">        174 :     pstmt-&gt;invalItems = NIL; /* workers can't replan anyway... */</span>
<span class="lineNum">     206 </span><span class="lineCov">        174 :     pstmt-&gt;paramExecTypes = estate-&gt;es_plannedstmt-&gt;paramExecTypes;</span>
<span class="lineNum">     207 </span><span class="lineCov">        174 :     pstmt-&gt;utilityStmt = NULL;</span>
<span class="lineNum">     208 </span><span class="lineCov">        174 :     pstmt-&gt;stmt_location = -1;</span>
<span class="lineNum">     209 </span><span class="lineCov">        174 :     pstmt-&gt;stmt_len = -1;</span>
<span class="lineNum">     210 </span>            : 
<span class="lineNum">     211 </span>            :     /* Return serialized copy of our dummy PlannedStmt. */
<span class="lineNum">     212 </span><span class="lineCov">        174 :     return nodeToString(pstmt);</span>
<span class="lineNum">     213 </span>            : }
<span class="lineNum">     214 </span>            : 
<span class="lineNum">     215 </span>            : /*
<span class="lineNum">     216 </span>            :  * Parallel-aware plan nodes (and occasionally others) may need some state
<span class="lineNum">     217 </span>            :  * which is shared across all parallel workers.  Before we size the DSM, give
<span class="lineNum">     218 </span>            :  * them a chance to call shm_toc_estimate_chunk or shm_toc_estimate_keys on
<span class="lineNum">     219 </span>            :  * &amp;pcxt-&gt;estimator.
<span class="lineNum">     220 </span>            :  *
<span class="lineNum">     221 </span>            :  * While we're at it, count the number of PlanState nodes in the tree, so
<span class="lineNum">     222 </span>            :  * we know how many Instrumentation structures we need.
<a name="223"><span class="lineNum">     223 </span>            :  */</a>
<span class="lineNum">     224 </span>            : static bool
<span class="lineNum">     225 </span><span class="lineCov">        818 : ExecParallelEstimate(PlanState *planstate, ExecParallelEstimateContext *e)</span>
<span class="lineNum">     226 </span>            : {
<span class="lineNum">     227 </span><span class="lineCov">        818 :     if (planstate == NULL)</span>
<span class="lineNum">     228 </span><span class="lineNoCov">          0 :         return false;</span>
<span class="lineNum">     229 </span>            : 
<span class="lineNum">     230 </span>            :     /* Count this node. */
<span class="lineNum">     231 </span><span class="lineCov">        818 :     e-&gt;nnodes++;</span>
<span class="lineNum">     232 </span>            : 
<span class="lineNum">     233 </span><span class="lineCov">        818 :     switch (nodeTag(planstate))</span>
<span class="lineNum">     234 </span>            :     {
<span class="lineNum">     235 </span>            :         case T_SeqScanState:
<span class="lineNum">     236 </span><span class="lineCov">        314 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     237 </span><span class="lineCov">        242 :                 ExecSeqScanEstimate((SeqScanState *) planstate,</span>
<span class="lineNum">     238 </span>            :                                     e-&gt;pcxt);
<span class="lineNum">     239 </span><span class="lineCov">        314 :             break;</span>
<span class="lineNum">     240 </span>            :         case T_IndexScanState:
<span class="lineNum">     241 </span><span class="lineCov">         96 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     242 </span><span class="lineCov">          4 :                 ExecIndexScanEstimate((IndexScanState *) planstate,</span>
<span class="lineNum">     243 </span>            :                                       e-&gt;pcxt);
<span class="lineNum">     244 </span><span class="lineCov">         96 :             break;</span>
<span class="lineNum">     245 </span>            :         case T_IndexOnlyScanState:
<span class="lineNum">     246 </span><span class="lineCov">         14 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     247 </span><span class="lineCov">         12 :                 ExecIndexOnlyScanEstimate((IndexOnlyScanState *) planstate,</span>
<span class="lineNum">     248 </span>            :                                           e-&gt;pcxt);
<span class="lineNum">     249 </span><span class="lineCov">         14 :             break;</span>
<span class="lineNum">     250 </span>            :         case T_ForeignScanState:
<span class="lineNum">     251 </span><span class="lineNoCov">          0 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     252 </span><span class="lineNoCov">          0 :                 ExecForeignScanEstimate((ForeignScanState *) planstate,</span>
<span class="lineNum">     253 </span>            :                                         e-&gt;pcxt);
<span class="lineNum">     254 </span><span class="lineNoCov">          0 :             break;</span>
<span class="lineNum">     255 </span>            :         case T_AppendState:
<span class="lineNum">     256 </span><span class="lineCov">         50 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     257 </span><span class="lineCov">         34 :                 ExecAppendEstimate((AppendState *) planstate,</span>
<span class="lineNum">     258 </span>            :                                    e-&gt;pcxt);
<span class="lineNum">     259 </span><span class="lineCov">         50 :             break;</span>
<span class="lineNum">     260 </span>            :         case T_CustomScanState:
<span class="lineNum">     261 </span><span class="lineNoCov">          0 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     262 </span><span class="lineNoCov">          0 :                 ExecCustomScanEstimate((CustomScanState *) planstate,</span>
<span class="lineNum">     263 </span>            :                                        e-&gt;pcxt);
<span class="lineNum">     264 </span><span class="lineNoCov">          0 :             break;</span>
<span class="lineNum">     265 </span>            :         case T_BitmapHeapScanState:
<span class="lineNum">     266 </span><span class="lineCov">          4 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     267 </span><span class="lineCov">          4 :                 ExecBitmapHeapEstimate((BitmapHeapScanState *) planstate,</span>
<span class="lineNum">     268 </span>            :                                        e-&gt;pcxt);
<span class="lineNum">     269 </span><span class="lineCov">          4 :             break;</span>
<span class="lineNum">     270 </span>            :         case T_HashJoinState:
<span class="lineNum">     271 </span><span class="lineCov">         56 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     272 </span><span class="lineCov">         32 :                 ExecHashJoinEstimate((HashJoinState *) planstate,</span>
<span class="lineNum">     273 </span>            :                                      e-&gt;pcxt);
<span class="lineNum">     274 </span><span class="lineCov">         56 :             break;</span>
<span class="lineNum">     275 </span>            :         case T_HashState:
<span class="lineNum">     276 </span>            :             /* even when not parallel-aware, for EXPLAIN ANALYZE */
<span class="lineNum">     277 </span><span class="lineCov">         56 :             ExecHashEstimate((HashState *) planstate, e-&gt;pcxt);</span>
<span class="lineNum">     278 </span><span class="lineCov">         56 :             break;</span>
<span class="lineNum">     279 </span>            :         case T_SortState:
<span class="lineNum">     280 </span>            :             /* even when not parallel-aware, for EXPLAIN ANALYZE */
<span class="lineNum">     281 </span><span class="lineCov">         42 :             ExecSortEstimate((SortState *) planstate, e-&gt;pcxt);</span>
<span class="lineNum">     282 </span><span class="lineCov">         42 :             break;</span>
<span class="lineNum">     283 </span>            : 
<span class="lineNum">     284 </span>            :         default:
<span class="lineNum">     285 </span><span class="lineCov">        186 :             break;</span>
<span class="lineNum">     286 </span>            :     }
<span class="lineNum">     287 </span>            : 
<span class="lineNum">     288 </span><span class="lineCov">        818 :     return planstate_tree_walker(planstate, ExecParallelEstimate, e);</span>
<span class="lineNum">     289 </span>            : }
<span class="lineNum">     290 </span>            : 
<span class="lineNum">     291 </span>            : /*
<span class="lineNum">     292 </span>            :  * Estimate the amount of space required to serialize the indicated parameters.
<a name="293"><span class="lineNum">     293 </span>            :  */</a>
<span class="lineNum">     294 </span>            : static Size
<span class="lineNum">     295 </span><span class="lineCov">          4 : EstimateParamExecSpace(EState *estate, Bitmapset *params)</span>
<span class="lineNum">     296 </span>            : {
<span class="lineNum">     297 </span>            :     int         paramid;
<span class="lineNum">     298 </span><span class="lineCov">          4 :     Size        sz = sizeof(int);</span>
<span class="lineNum">     299 </span>            : 
<span class="lineNum">     300 </span><span class="lineCov">          4 :     paramid = -1;</span>
<span class="lineNum">     301 </span><span class="lineCov">         14 :     while ((paramid = bms_next_member(params, paramid)) &gt;= 0)</span>
<span class="lineNum">     302 </span>            :     {
<span class="lineNum">     303 </span>            :         Oid         typeOid;
<span class="lineNum">     304 </span>            :         int16       typLen;
<span class="lineNum">     305 </span>            :         bool        typByVal;
<span class="lineNum">     306 </span>            :         ParamExecData *prm;
<span class="lineNum">     307 </span>            : 
<span class="lineNum">     308 </span><span class="lineCov">          6 :         prm = &amp;(estate-&gt;es_param_exec_vals[paramid]);</span>
<span class="lineNum">     309 </span><span class="lineCov">          6 :         typeOid = list_nth_oid(estate-&gt;es_plannedstmt-&gt;paramExecTypes,</span>
<span class="lineNum">     310 </span>            :                                paramid);
<span class="lineNum">     311 </span>            : 
<span class="lineNum">     312 </span><span class="lineCov">          6 :         sz = add_size(sz, sizeof(int)); /* space for paramid */</span>
<span class="lineNum">     313 </span>            : 
<span class="lineNum">     314 </span>            :         /* space for datum/isnull */
<span class="lineNum">     315 </span><span class="lineCov">          6 :         if (OidIsValid(typeOid))</span>
<span class="lineNum">     316 </span><span class="lineCov">          6 :             get_typlenbyval(typeOid, &amp;typLen, &amp;typByVal);</span>
<span class="lineNum">     317 </span>            :         else
<span class="lineNum">     318 </span>            :         {
<span class="lineNum">     319 </span>            :             /* If no type OID, assume by-value, like copyParamList does. */
<span class="lineNum">     320 </span><span class="lineNoCov">          0 :             typLen = sizeof(Datum);</span>
<span class="lineNum">     321 </span><span class="lineNoCov">          0 :             typByVal = true;</span>
<span class="lineNum">     322 </span>            :         }
<span class="lineNum">     323 </span><span class="lineCov">         12 :         sz = add_size(sz,</span>
<span class="lineNum">     324 </span><span class="lineCov">          6 :                       datumEstimateSpace(prm-&gt;value, prm-&gt;isnull,</span>
<span class="lineNum">     325 </span>            :                                          typByVal, typLen));
<span class="lineNum">     326 </span>            :     }
<span class="lineNum">     327 </span><span class="lineCov">          4 :     return sz;</span>
<span class="lineNum">     328 </span>            : }
<span class="lineNum">     329 </span>            : 
<span class="lineNum">     330 </span>            : /*
<span class="lineNum">     331 </span>            :  * Serialize specified PARAM_EXEC parameters.
<span class="lineNum">     332 </span>            :  *
<span class="lineNum">     333 </span>            :  * We write the number of parameters first, as a 4-byte integer, and then
<span class="lineNum">     334 </span>            :  * write details for each parameter in turn.  The details for each parameter
<span class="lineNum">     335 </span>            :  * consist of a 4-byte paramid (location of param in execution time internal
<span class="lineNum">     336 </span>            :  * parameter array) and then the datum as serialized by datumSerialize().
<a name="337"><span class="lineNum">     337 </span>            :  */</a>
<span class="lineNum">     338 </span>            : static dsa_pointer
<span class="lineNum">     339 </span><span class="lineCov">          4 : SerializeParamExecParams(EState *estate, Bitmapset *params, dsa_area *area)</span>
<span class="lineNum">     340 </span>            : {
<span class="lineNum">     341 </span>            :     Size        size;
<span class="lineNum">     342 </span>            :     int         nparams;
<span class="lineNum">     343 </span>            :     int         paramid;
<span class="lineNum">     344 </span>            :     ParamExecData *prm;
<span class="lineNum">     345 </span>            :     dsa_pointer handle;
<span class="lineNum">     346 </span>            :     char       *start_address;
<span class="lineNum">     347 </span>            : 
<span class="lineNum">     348 </span>            :     /* Allocate enough space for the current parameter values. */
<span class="lineNum">     349 </span><span class="lineCov">          4 :     size = EstimateParamExecSpace(estate, params);</span>
<span class="lineNum">     350 </span><span class="lineCov">          4 :     handle = dsa_allocate(area, size);</span>
<span class="lineNum">     351 </span><span class="lineCov">          4 :     start_address = dsa_get_address(area, handle);</span>
<span class="lineNum">     352 </span>            : 
<span class="lineNum">     353 </span>            :     /* First write the number of parameters as a 4-byte integer. */
<span class="lineNum">     354 </span><span class="lineCov">          4 :     nparams = bms_num_members(params);</span>
<span class="lineNum">     355 </span><span class="lineCov">          4 :     memcpy(start_address, &amp;nparams, sizeof(int));</span>
<span class="lineNum">     356 </span><span class="lineCov">          4 :     start_address += sizeof(int);</span>
<span class="lineNum">     357 </span>            : 
<span class="lineNum">     358 </span>            :     /* Write details for each parameter in turn. */
<span class="lineNum">     359 </span><span class="lineCov">          4 :     paramid = -1;</span>
<span class="lineNum">     360 </span><span class="lineCov">         14 :     while ((paramid = bms_next_member(params, paramid)) &gt;= 0)</span>
<span class="lineNum">     361 </span>            :     {
<span class="lineNum">     362 </span>            :         Oid         typeOid;
<span class="lineNum">     363 </span>            :         int16       typLen;
<span class="lineNum">     364 </span>            :         bool        typByVal;
<span class="lineNum">     365 </span>            : 
<span class="lineNum">     366 </span><span class="lineCov">          6 :         prm = &amp;(estate-&gt;es_param_exec_vals[paramid]);</span>
<span class="lineNum">     367 </span><span class="lineCov">          6 :         typeOid = list_nth_oid(estate-&gt;es_plannedstmt-&gt;paramExecTypes,</span>
<span class="lineNum">     368 </span>            :                                paramid);
<span class="lineNum">     369 </span>            : 
<span class="lineNum">     370 </span>            :         /* Write paramid. */
<span class="lineNum">     371 </span><span class="lineCov">          6 :         memcpy(start_address, &amp;paramid, sizeof(int));</span>
<span class="lineNum">     372 </span><span class="lineCov">          6 :         start_address += sizeof(int);</span>
<span class="lineNum">     373 </span>            : 
<span class="lineNum">     374 </span>            :         /* Write datum/isnull */
<span class="lineNum">     375 </span><span class="lineCov">          6 :         if (OidIsValid(typeOid))</span>
<span class="lineNum">     376 </span><span class="lineCov">          6 :             get_typlenbyval(typeOid, &amp;typLen, &amp;typByVal);</span>
<span class="lineNum">     377 </span>            :         else
<span class="lineNum">     378 </span>            :         {
<span class="lineNum">     379 </span>            :             /* If no type OID, assume by-value, like copyParamList does. */
<span class="lineNum">     380 </span><span class="lineNoCov">          0 :             typLen = sizeof(Datum);</span>
<span class="lineNum">     381 </span><span class="lineNoCov">          0 :             typByVal = true;</span>
<span class="lineNum">     382 </span>            :         }
<span class="lineNum">     383 </span><span class="lineCov">          6 :         datumSerialize(prm-&gt;value, prm-&gt;isnull, typByVal, typLen,</span>
<span class="lineNum">     384 </span>            :                        &amp;start_address);
<span class="lineNum">     385 </span>            :     }
<span class="lineNum">     386 </span>            : 
<span class="lineNum">     387 </span><span class="lineCov">          4 :     return handle;</span>
<span class="lineNum">     388 </span>            : }
<span class="lineNum">     389 </span>            : 
<span class="lineNum">     390 </span>            : /*
<span class="lineNum">     391 </span>            :  * Restore specified PARAM_EXEC parameters.
<a name="392"><span class="lineNum">     392 </span>            :  */</a>
<span class="lineNum">     393 </span>            : static void
<span class="lineNum">     394 </span><span class="lineCov">         12 : RestoreParamExecParams(char *start_address, EState *estate)</span>
<span class="lineNum">     395 </span>            : {
<span class="lineNum">     396 </span>            :     int         nparams;
<span class="lineNum">     397 </span>            :     int         i;
<span class="lineNum">     398 </span>            :     int         paramid;
<span class="lineNum">     399 </span>            : 
<span class="lineNum">     400 </span><span class="lineCov">         12 :     memcpy(&amp;nparams, start_address, sizeof(int));</span>
<span class="lineNum">     401 </span><span class="lineCov">         12 :     start_address += sizeof(int);</span>
<span class="lineNum">     402 </span>            : 
<span class="lineNum">     403 </span><span class="lineCov">         28 :     for (i = 0; i &lt; nparams; i++)</span>
<span class="lineNum">     404 </span>            :     {
<span class="lineNum">     405 </span>            :         ParamExecData *prm;
<span class="lineNum">     406 </span>            : 
<span class="lineNum">     407 </span>            :         /* Read paramid */
<span class="lineNum">     408 </span><span class="lineCov">         16 :         memcpy(&amp;paramid, start_address, sizeof(int));</span>
<span class="lineNum">     409 </span><span class="lineCov">         16 :         start_address += sizeof(int);</span>
<span class="lineNum">     410 </span><span class="lineCov">         16 :         prm = &amp;(estate-&gt;es_param_exec_vals[paramid]);</span>
<span class="lineNum">     411 </span>            : 
<span class="lineNum">     412 </span>            :         /* Read datum/isnull. */
<span class="lineNum">     413 </span><span class="lineCov">         16 :         prm-&gt;value = datumRestore(&amp;start_address, &amp;prm-&gt;isnull);</span>
<span class="lineNum">     414 </span><span class="lineCov">         16 :         prm-&gt;execPlan = NULL;</span>
<span class="lineNum">     415 </span>            :     }
<span class="lineNum">     416 </span><span class="lineCov">         12 : }</span>
<span class="lineNum">     417 </span>            : 
<span class="lineNum">     418 </span>            : /*
<span class="lineNum">     419 </span>            :  * Initialize the dynamic shared memory segment that will be used to control
<span class="lineNum">     420 </span>            :  * parallel execution.
<a name="421"><span class="lineNum">     421 </span>            :  */</a>
<span class="lineNum">     422 </span>            : static bool
<span class="lineNum">     423 </span><span class="lineCov">        818 : ExecParallelInitializeDSM(PlanState *planstate,</span>
<span class="lineNum">     424 </span>            :                           ExecParallelInitializeDSMContext *d)
<span class="lineNum">     425 </span>            : {
<span class="lineNum">     426 </span><span class="lineCov">        818 :     if (planstate == NULL)</span>
<span class="lineNum">     427 </span><span class="lineNoCov">          0 :         return false;</span>
<span class="lineNum">     428 </span>            : 
<span class="lineNum">     429 </span>            :     /* If instrumentation is enabled, initialize slot for this node. */
<span class="lineNum">     430 </span><span class="lineCov">        818 :     if (d-&gt;instrumentation != NULL)</span>
<span class="lineNum">     431 </span><span class="lineCov">        636 :         d-&gt;instrumentation-&gt;plan_node_id[d-&gt;nnodes] =</span>
<span class="lineNum">     432 </span><span class="lineCov">        318 :             planstate-&gt;plan-&gt;plan_node_id;</span>
<span class="lineNum">     433 </span>            : 
<span class="lineNum">     434 </span>            :     /* Count this node. */
<span class="lineNum">     435 </span><span class="lineCov">        818 :     d-&gt;nnodes++;</span>
<span class="lineNum">     436 </span>            : 
<span class="lineNum">     437 </span>            :     /*
<span class="lineNum">     438 </span>            :      * Call initializers for DSM-using plan nodes.
<span class="lineNum">     439 </span>            :      *
<span class="lineNum">     440 </span>            :      * Most plan nodes won't do anything here, but plan nodes that allocated
<span class="lineNum">     441 </span>            :      * DSM may need to initialize shared state in the DSM before parallel
<span class="lineNum">     442 </span>            :      * workers are launched.  They can allocate the space they previously
<span class="lineNum">     443 </span>            :      * estimated using shm_toc_allocate, and add the keys they previously
<span class="lineNum">     444 </span>            :      * estimated using shm_toc_insert, in each case targeting pcxt-&gt;toc.
<span class="lineNum">     445 </span>            :      */
<span class="lineNum">     446 </span><span class="lineCov">        818 :     switch (nodeTag(planstate))</span>
<span class="lineNum">     447 </span>            :     {
<span class="lineNum">     448 </span>            :         case T_SeqScanState:
<span class="lineNum">     449 </span><span class="lineCov">        314 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     450 </span><span class="lineCov">        242 :                 ExecSeqScanInitializeDSM((SeqScanState *) planstate,</span>
<span class="lineNum">     451 </span>            :                                          d-&gt;pcxt);
<span class="lineNum">     452 </span><span class="lineCov">        314 :             break;</span>
<span class="lineNum">     453 </span>            :         case T_IndexScanState:
<span class="lineNum">     454 </span><span class="lineCov">         96 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     455 </span><span class="lineCov">          4 :                 ExecIndexScanInitializeDSM((IndexScanState *) planstate,</span>
<span class="lineNum">     456 </span>            :                                            d-&gt;pcxt);
<span class="lineNum">     457 </span><span class="lineCov">         96 :             break;</span>
<span class="lineNum">     458 </span>            :         case T_IndexOnlyScanState:
<span class="lineNum">     459 </span><span class="lineCov">         14 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     460 </span><span class="lineCov">         12 :                 ExecIndexOnlyScanInitializeDSM((IndexOnlyScanState *) planstate,</span>
<span class="lineNum">     461 </span>            :                                                d-&gt;pcxt);
<span class="lineNum">     462 </span><span class="lineCov">         14 :             break;</span>
<span class="lineNum">     463 </span>            :         case T_ForeignScanState:
<span class="lineNum">     464 </span><span class="lineNoCov">          0 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     465 </span><span class="lineNoCov">          0 :                 ExecForeignScanInitializeDSM((ForeignScanState *) planstate,</span>
<span class="lineNum">     466 </span>            :                                              d-&gt;pcxt);
<span class="lineNum">     467 </span><span class="lineNoCov">          0 :             break;</span>
<span class="lineNum">     468 </span>            :         case T_AppendState:
<span class="lineNum">     469 </span><span class="lineCov">         50 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     470 </span><span class="lineCov">         34 :                 ExecAppendInitializeDSM((AppendState *) planstate,</span>
<span class="lineNum">     471 </span>            :                                         d-&gt;pcxt);
<span class="lineNum">     472 </span><span class="lineCov">         50 :             break;</span>
<span class="lineNum">     473 </span>            :         case T_CustomScanState:
<span class="lineNum">     474 </span><span class="lineNoCov">          0 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     475 </span><span class="lineNoCov">          0 :                 ExecCustomScanInitializeDSM((CustomScanState *) planstate,</span>
<span class="lineNum">     476 </span>            :                                             d-&gt;pcxt);
<span class="lineNum">     477 </span><span class="lineNoCov">          0 :             break;</span>
<span class="lineNum">     478 </span>            :         case T_BitmapHeapScanState:
<span class="lineNum">     479 </span><span class="lineCov">          4 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     480 </span><span class="lineCov">          4 :                 ExecBitmapHeapInitializeDSM((BitmapHeapScanState *) planstate,</span>
<span class="lineNum">     481 </span>            :                                             d-&gt;pcxt);
<span class="lineNum">     482 </span><span class="lineCov">          4 :             break;</span>
<span class="lineNum">     483 </span>            :         case T_HashJoinState:
<span class="lineNum">     484 </span><span class="lineCov">         56 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     485 </span><span class="lineCov">         32 :                 ExecHashJoinInitializeDSM((HashJoinState *) planstate,</span>
<span class="lineNum">     486 </span>            :                                           d-&gt;pcxt);
<span class="lineNum">     487 </span><span class="lineCov">         56 :             break;</span>
<span class="lineNum">     488 </span>            :         case T_HashState:
<span class="lineNum">     489 </span>            :             /* even when not parallel-aware, for EXPLAIN ANALYZE */
<span class="lineNum">     490 </span><span class="lineCov">         56 :             ExecHashInitializeDSM((HashState *) planstate, d-&gt;pcxt);</span>
<span class="lineNum">     491 </span><span class="lineCov">         56 :             break;</span>
<span class="lineNum">     492 </span>            :         case T_SortState:
<span class="lineNum">     493 </span>            :             /* even when not parallel-aware, for EXPLAIN ANALYZE */
<span class="lineNum">     494 </span><span class="lineCov">         42 :             ExecSortInitializeDSM((SortState *) planstate, d-&gt;pcxt);</span>
<span class="lineNum">     495 </span><span class="lineCov">         42 :             break;</span>
<span class="lineNum">     496 </span>            : 
<span class="lineNum">     497 </span>            :         default:
<span class="lineNum">     498 </span><span class="lineCov">        186 :             break;</span>
<span class="lineNum">     499 </span>            :     }
<span class="lineNum">     500 </span>            : 
<span class="lineNum">     501 </span><span class="lineCov">        818 :     return planstate_tree_walker(planstate, ExecParallelInitializeDSM, d);</span>
<span class="lineNum">     502 </span>            : }
<span class="lineNum">     503 </span>            : 
<span class="lineNum">     504 </span>            : /*
<span class="lineNum">     505 </span>            :  * It sets up the response queues for backend workers to return tuples
<span class="lineNum">     506 </span>            :  * to the main backend and start the workers.
<a name="507"><span class="lineNum">     507 </span>            :  */</a>
<span class="lineNum">     508 </span>            : static shm_mq_handle **
<span class="lineNum">     509 </span><span class="lineCov">        258 : ExecParallelSetupTupleQueues(ParallelContext *pcxt, bool reinitialize)</span>
<span class="lineNum">     510 </span>            : {
<span class="lineNum">     511 </span>            :     shm_mq_handle **responseq;
<span class="lineNum">     512 </span>            :     char       *tqueuespace;
<span class="lineNum">     513 </span>            :     int         i;
<span class="lineNum">     514 </span>            : 
<span class="lineNum">     515 </span>            :     /* Skip this if no workers. */
<span class="lineNum">     516 </span><span class="lineCov">        258 :     if (pcxt-&gt;nworkers == 0)</span>
<span class="lineNum">     517 </span><span class="lineNoCov">          0 :         return NULL;</span>
<span class="lineNum">     518 </span>            : 
<span class="lineNum">     519 </span>            :     /* Allocate memory for shared memory queue handles. */
<span class="lineNum">     520 </span><span class="lineCov">        258 :     responseq = (shm_mq_handle **)</span>
<span class="lineNum">     521 </span><span class="lineCov">        258 :         palloc(pcxt-&gt;nworkers * sizeof(shm_mq_handle *));</span>
<span class="lineNum">     522 </span>            : 
<span class="lineNum">     523 </span>            :     /*
<span class="lineNum">     524 </span>            :      * If not reinitializing, allocate space from the DSM for the queues;
<span class="lineNum">     525 </span>            :      * otherwise, find the already allocated space.
<span class="lineNum">     526 </span>            :      */
<span class="lineNum">     527 </span><span class="lineCov">        258 :     if (!reinitialize)</span>
<span class="lineNum">     528 </span><span class="lineCov">        174 :         tqueuespace =</span>
<span class="lineNum">     529 </span><span class="lineCov">        174 :             shm_toc_allocate(pcxt-&gt;toc,</span>
<span class="lineNum">     530 </span>            :                              mul_size(PARALLEL_TUPLE_QUEUE_SIZE,
<span class="lineNum">     531 </span><span class="lineCov">        174 :                                       pcxt-&gt;nworkers));</span>
<span class="lineNum">     532 </span>            :     else
<span class="lineNum">     533 </span><span class="lineCov">         84 :         tqueuespace = shm_toc_lookup(pcxt-&gt;toc, PARALLEL_KEY_TUPLE_QUEUE, false);</span>
<span class="lineNum">     534 </span>            : 
<span class="lineNum">     535 </span>            :     /* Create the queues, and become the receiver for each. */
<span class="lineNum">     536 </span><span class="lineCov">        988 :     for (i = 0; i &lt; pcxt-&gt;nworkers; ++i)</span>
<span class="lineNum">     537 </span>            :     {
<span class="lineNum">     538 </span>            :         shm_mq     *mq;
<span class="lineNum">     539 </span>            : 
<span class="lineNum">     540 </span><span class="lineCov">        730 :         mq = shm_mq_create(tqueuespace +</span>
<span class="lineNum">     541 </span><span class="lineCov">        730 :                            ((Size) i) * PARALLEL_TUPLE_QUEUE_SIZE,</span>
<span class="lineNum">     542 </span>            :                            (Size) PARALLEL_TUPLE_QUEUE_SIZE);
<span class="lineNum">     543 </span>            : 
<span class="lineNum">     544 </span><span class="lineCov">        730 :         shm_mq_set_receiver(mq, MyProc);</span>
<span class="lineNum">     545 </span><span class="lineCov">        730 :         responseq[i] = shm_mq_attach(mq, pcxt-&gt;seg, NULL);</span>
<span class="lineNum">     546 </span>            :     }
<span class="lineNum">     547 </span>            : 
<span class="lineNum">     548 </span>            :     /* Add array of queues to shm_toc, so others can find it. */
<span class="lineNum">     549 </span><span class="lineCov">        258 :     if (!reinitialize)</span>
<span class="lineNum">     550 </span><span class="lineCov">        174 :         shm_toc_insert(pcxt-&gt;toc, PARALLEL_KEY_TUPLE_QUEUE, tqueuespace);</span>
<span class="lineNum">     551 </span>            : 
<span class="lineNum">     552 </span>            :     /* Return array of handles. */
<span class="lineNum">     553 </span><span class="lineCov">        258 :     return responseq;</span>
<span class="lineNum">     554 </span>            : }
<span class="lineNum">     555 </span>            : 
<span class="lineNum">     556 </span>            : /*
<span class="lineNum">     557 </span>            :  * Sets up the required infrastructure for backend workers to perform
<span class="lineNum">     558 </span>            :  * execution and return results to the main backend.
<a name="559"><span class="lineNum">     559 </span>            :  */</a>
<span class="lineNum">     560 </span>            : ParallelExecutorInfo *
<span class="lineNum">     561 </span><span class="lineCov">        174 : ExecInitParallelPlan(PlanState *planstate, EState *estate,</span>
<span class="lineNum">     562 </span>            :                      Bitmapset *sendParams, int nworkers,
<span class="lineNum">     563 </span>            :                      int64 tuples_needed)
<span class="lineNum">     564 </span>            : {
<span class="lineNum">     565 </span>            :     ParallelExecutorInfo *pei;
<span class="lineNum">     566 </span>            :     ParallelContext *pcxt;
<span class="lineNum">     567 </span>            :     ExecParallelEstimateContext e;
<span class="lineNum">     568 </span>            :     ExecParallelInitializeDSMContext d;
<span class="lineNum">     569 </span>            :     FixedParallelExecutorState *fpes;
<span class="lineNum">     570 </span>            :     char       *pstmt_data;
<span class="lineNum">     571 </span>            :     char       *pstmt_space;
<span class="lineNum">     572 </span>            :     char       *paramlistinfo_space;
<span class="lineNum">     573 </span>            :     BufferUsage *bufusage_space;
<span class="lineNum">     574 </span><span class="lineCov">        174 :     SharedExecutorInstrumentation *instrumentation = NULL;</span>
<span class="lineNum">     575 </span><span class="lineCov">        174 :     SharedJitInstrumentation *jit_instrumentation = NULL;</span>
<span class="lineNum">     576 </span>            :     int         pstmt_len;
<span class="lineNum">     577 </span>            :     int         paramlistinfo_len;
<span class="lineNum">     578 </span><span class="lineCov">        174 :     int         instrumentation_len = 0;</span>
<span class="lineNum">     579 </span><span class="lineCov">        174 :     int         jit_instrumentation_len = 0;</span>
<span class="lineNum">     580 </span><span class="lineCov">        174 :     int         instrument_offset = 0;</span>
<span class="lineNum">     581 </span><span class="lineCov">        174 :     Size        dsa_minsize = dsa_minimum_size();</span>
<span class="lineNum">     582 </span>            :     char       *query_string;
<span class="lineNum">     583 </span>            :     int         query_len;
<span class="lineNum">     584 </span>            : 
<span class="lineNum">     585 </span>            :     /*
<span class="lineNum">     586 </span>            :      * Force any initplan outputs that we're going to pass to workers to be
<span class="lineNum">     587 </span>            :      * evaluated, if they weren't already.
<span class="lineNum">     588 </span>            :      *
<span class="lineNum">     589 </span>            :      * For simplicity, we use the EState's per-output-tuple ExprContext here.
<span class="lineNum">     590 </span>            :      * That risks intra-query memory leakage, since we might pass through here
<span class="lineNum">     591 </span>            :      * many times before that ExprContext gets reset; but ExecSetParamPlan
<span class="lineNum">     592 </span>            :      * doesn't normally leak any memory in the context (see its comments), so
<span class="lineNum">     593 </span>            :      * it doesn't seem worth complicating this function's API to pass it a
<span class="lineNum">     594 </span>            :      * shorter-lived ExprContext.  This might need to change someday.
<span class="lineNum">     595 </span>            :      */
<span class="lineNum">     596 </span><span class="lineCov">        174 :     ExecSetParamPlanMulti(sendParams, GetPerTupleExprContext(estate));</span>
<span class="lineNum">     597 </span>            : 
<span class="lineNum">     598 </span>            :     /* Allocate object for return value. */
<span class="lineNum">     599 </span><span class="lineCov">        174 :     pei = palloc0(sizeof(ParallelExecutorInfo));</span>
<span class="lineNum">     600 </span><span class="lineCov">        174 :     pei-&gt;finished = false;</span>
<span class="lineNum">     601 </span><span class="lineCov">        174 :     pei-&gt;planstate = planstate;</span>
<span class="lineNum">     602 </span>            : 
<span class="lineNum">     603 </span>            :     /* Fix up and serialize plan to be sent to workers. */
<span class="lineNum">     604 </span><span class="lineCov">        174 :     pstmt_data = ExecSerializePlan(planstate-&gt;plan, estate);</span>
<span class="lineNum">     605 </span>            : 
<span class="lineNum">     606 </span>            :     /* Create a parallel context. */
<span class="lineNum">     607 </span><span class="lineCov">        174 :     pcxt = CreateParallelContext(&quot;postgres&quot;, &quot;ParallelQueryMain&quot;, nworkers);</span>
<span class="lineNum">     608 </span><span class="lineCov">        174 :     pei-&gt;pcxt = pcxt;</span>
<span class="lineNum">     609 </span>            : 
<span class="lineNum">     610 </span>            :     /*
<span class="lineNum">     611 </span>            :      * Before telling the parallel context to create a dynamic shared memory
<span class="lineNum">     612 </span>            :      * segment, we need to figure out how big it should be.  Estimate space
<span class="lineNum">     613 </span>            :      * for the various things we need to store.
<span class="lineNum">     614 </span>            :      */
<span class="lineNum">     615 </span>            : 
<span class="lineNum">     616 </span>            :     /* Estimate space for fixed-size state. */
<span class="lineNum">     617 </span><span class="lineCov">        174 :     shm_toc_estimate_chunk(&amp;pcxt-&gt;estimator,</span>
<span class="lineNum">     618 </span>            :                            sizeof(FixedParallelExecutorState));
<span class="lineNum">     619 </span><span class="lineCov">        174 :     shm_toc_estimate_keys(&amp;pcxt-&gt;estimator, 1);</span>
<span class="lineNum">     620 </span>            : 
<span class="lineNum">     621 </span>            :     /* Estimate space for query text. */
<span class="lineNum">     622 </span><span class="lineCov">        174 :     query_len = strlen(estate-&gt;es_sourceText);</span>
<span class="lineNum">     623 </span><span class="lineCov">        174 :     shm_toc_estimate_chunk(&amp;pcxt-&gt;estimator, query_len + 1);</span>
<span class="lineNum">     624 </span><span class="lineCov">        174 :     shm_toc_estimate_keys(&amp;pcxt-&gt;estimator, 1);</span>
<span class="lineNum">     625 </span>            : 
<span class="lineNum">     626 </span>            :     /* Estimate space for serialized PlannedStmt. */
<span class="lineNum">     627 </span><span class="lineCov">        174 :     pstmt_len = strlen(pstmt_data) + 1;</span>
<span class="lineNum">     628 </span><span class="lineCov">        174 :     shm_toc_estimate_chunk(&amp;pcxt-&gt;estimator, pstmt_len);</span>
<span class="lineNum">     629 </span><span class="lineCov">        174 :     shm_toc_estimate_keys(&amp;pcxt-&gt;estimator, 1);</span>
<span class="lineNum">     630 </span>            : 
<span class="lineNum">     631 </span>            :     /* Estimate space for serialized ParamListInfo. */
<span class="lineNum">     632 </span><span class="lineCov">        174 :     paramlistinfo_len = EstimateParamListSpace(estate-&gt;es_param_list_info);</span>
<span class="lineNum">     633 </span><span class="lineCov">        174 :     shm_toc_estimate_chunk(&amp;pcxt-&gt;estimator, paramlistinfo_len);</span>
<span class="lineNum">     634 </span><span class="lineCov">        174 :     shm_toc_estimate_keys(&amp;pcxt-&gt;estimator, 1);</span>
<span class="lineNum">     635 </span>            : 
<span class="lineNum">     636 </span>            :     /*
<span class="lineNum">     637 </span>            :      * Estimate space for BufferUsage.
<span class="lineNum">     638 </span>            :      *
<span class="lineNum">     639 </span>            :      * If EXPLAIN is not in use and there are no extensions loaded that care,
<span class="lineNum">     640 </span>            :      * we could skip this.  But we have no way of knowing whether anyone's
<span class="lineNum">     641 </span>            :      * looking at pgBufferUsage, so do it unconditionally.
<span class="lineNum">     642 </span>            :      */
<span class="lineNum">     643 </span><span class="lineCov">        174 :     shm_toc_estimate_chunk(&amp;pcxt-&gt;estimator,</span>
<span class="lineNum">     644 </span>            :                            mul_size(sizeof(BufferUsage), pcxt-&gt;nworkers));
<span class="lineNum">     645 </span><span class="lineCov">        174 :     shm_toc_estimate_keys(&amp;pcxt-&gt;estimator, 1);</span>
<span class="lineNum">     646 </span>            : 
<span class="lineNum">     647 </span>            :     /* Estimate space for tuple queues. */
<span class="lineNum">     648 </span><span class="lineCov">        174 :     shm_toc_estimate_chunk(&amp;pcxt-&gt;estimator,</span>
<span class="lineNum">     649 </span>            :                            mul_size(PARALLEL_TUPLE_QUEUE_SIZE, pcxt-&gt;nworkers));
<span class="lineNum">     650 </span><span class="lineCov">        174 :     shm_toc_estimate_keys(&amp;pcxt-&gt;estimator, 1);</span>
<span class="lineNum">     651 </span>            : 
<span class="lineNum">     652 </span>            :     /*
<span class="lineNum">     653 </span>            :      * Give parallel-aware nodes a chance to add to the estimates, and get a
<span class="lineNum">     654 </span>            :      * count of how many PlanState nodes there are.
<span class="lineNum">     655 </span>            :      */
<span class="lineNum">     656 </span><span class="lineCov">        174 :     e.pcxt = pcxt;</span>
<span class="lineNum">     657 </span><span class="lineCov">        174 :     e.nnodes = 0;</span>
<span class="lineNum">     658 </span><span class="lineCov">        174 :     ExecParallelEstimate(planstate, &amp;e);</span>
<span class="lineNum">     659 </span>            : 
<span class="lineNum">     660 </span>            :     /* Estimate space for instrumentation, if required. */
<span class="lineNum">     661 </span><span class="lineCov">        174 :     if (estate-&gt;es_instrument)</span>
<span class="lineNum">     662 </span>            :     {
<span class="lineNum">     663 </span><span class="lineCov">         54 :         instrumentation_len =</span>
<span class="lineNum">     664 </span>            :             offsetof(SharedExecutorInstrumentation, plan_node_id) +
<span class="lineNum">     665 </span><span class="lineCov">         54 :             sizeof(int) * e.nnodes;</span>
<span class="lineNum">     666 </span><span class="lineCov">         54 :         instrumentation_len = MAXALIGN(instrumentation_len);</span>
<span class="lineNum">     667 </span><span class="lineCov">         54 :         instrument_offset = instrumentation_len;</span>
<span class="lineNum">     668 </span><span class="lineCov">         54 :         instrumentation_len +=</span>
<span class="lineNum">     669 </span><span class="lineCov">        108 :             mul_size(sizeof(Instrumentation),</span>
<span class="lineNum">     670 </span><span class="lineCov">         54 :                      mul_size(e.nnodes, nworkers));</span>
<span class="lineNum">     671 </span><span class="lineCov">         54 :         shm_toc_estimate_chunk(&amp;pcxt-&gt;estimator, instrumentation_len);</span>
<span class="lineNum">     672 </span><span class="lineCov">         54 :         shm_toc_estimate_keys(&amp;pcxt-&gt;estimator, 1);</span>
<span class="lineNum">     673 </span>            : 
<span class="lineNum">     674 </span>            :         /* Estimate space for JIT instrumentation, if required. */
<span class="lineNum">     675 </span><span class="lineCov">         54 :         if (estate-&gt;es_jit_flags != PGJIT_NONE)</span>
<span class="lineNum">     676 </span>            :         {
<span class="lineNum">     677 </span><span class="lineCov">          8 :             jit_instrumentation_len =</span>
<span class="lineNum">     678 </span>            :                 offsetof(SharedJitInstrumentation, jit_instr) +
<span class="lineNum">     679 </span>            :                 sizeof(JitInstrumentation) * nworkers;
<span class="lineNum">     680 </span><span class="lineCov">          8 :             shm_toc_estimate_chunk(&amp;pcxt-&gt;estimator, jit_instrumentation_len);</span>
<span class="lineNum">     681 </span><span class="lineCov">          8 :             shm_toc_estimate_keys(&amp;pcxt-&gt;estimator, 1);</span>
<span class="lineNum">     682 </span>            :         }
<span class="lineNum">     683 </span>            :     }
<span class="lineNum">     684 </span>            : 
<span class="lineNum">     685 </span>            :     /* Estimate space for DSA area. */
<span class="lineNum">     686 </span><span class="lineCov">        174 :     shm_toc_estimate_chunk(&amp;pcxt-&gt;estimator, dsa_minsize);</span>
<span class="lineNum">     687 </span><span class="lineCov">        174 :     shm_toc_estimate_keys(&amp;pcxt-&gt;estimator, 1);</span>
<span class="lineNum">     688 </span>            : 
<span class="lineNum">     689 </span>            :     /* Everyone's had a chance to ask for space, so now create the DSM. */
<span class="lineNum">     690 </span><span class="lineCov">        174 :     InitializeParallelDSM(pcxt);</span>
<span class="lineNum">     691 </span>            : 
<span class="lineNum">     692 </span>            :     /*
<span class="lineNum">     693 </span>            :      * OK, now we have a dynamic shared memory segment, and it should be big
<span class="lineNum">     694 </span>            :      * enough to store all of the data we estimated we would want to put into
<span class="lineNum">     695 </span>            :      * it, plus whatever general stuff (not specifically executor-related) the
<span class="lineNum">     696 </span>            :      * ParallelContext itself needs to store there.  None of the space we
<span class="lineNum">     697 </span>            :      * asked for has been allocated or initialized yet, though, so do that.
<span class="lineNum">     698 </span>            :      */
<span class="lineNum">     699 </span>            : 
<span class="lineNum">     700 </span>            :     /* Store fixed-size state. */
<span class="lineNum">     701 </span><span class="lineCov">        174 :     fpes = shm_toc_allocate(pcxt-&gt;toc, sizeof(FixedParallelExecutorState));</span>
<span class="lineNum">     702 </span><span class="lineCov">        174 :     fpes-&gt;tuples_needed = tuples_needed;</span>
<span class="lineNum">     703 </span><span class="lineCov">        174 :     fpes-&gt;param_exec = InvalidDsaPointer;</span>
<span class="lineNum">     704 </span><span class="lineCov">        174 :     fpes-&gt;eflags = estate-&gt;es_top_eflags;</span>
<span class="lineNum">     705 </span><span class="lineCov">        174 :     fpes-&gt;jit_flags = estate-&gt;es_jit_flags;</span>
<span class="lineNum">     706 </span><span class="lineCov">        174 :     shm_toc_insert(pcxt-&gt;toc, PARALLEL_KEY_EXECUTOR_FIXED, fpes);</span>
<span class="lineNum">     707 </span>            : 
<span class="lineNum">     708 </span>            :     /* Store query string */
<span class="lineNum">     709 </span><span class="lineCov">        174 :     query_string = shm_toc_allocate(pcxt-&gt;toc, query_len + 1);</span>
<span class="lineNum">     710 </span><span class="lineCov">        174 :     memcpy(query_string, estate-&gt;es_sourceText, query_len + 1);</span>
<span class="lineNum">     711 </span><span class="lineCov">        174 :     shm_toc_insert(pcxt-&gt;toc, PARALLEL_KEY_QUERY_TEXT, query_string);</span>
<span class="lineNum">     712 </span>            : 
<span class="lineNum">     713 </span>            :     /* Store serialized PlannedStmt. */
<span class="lineNum">     714 </span><span class="lineCov">        174 :     pstmt_space = shm_toc_allocate(pcxt-&gt;toc, pstmt_len);</span>
<span class="lineNum">     715 </span><span class="lineCov">        174 :     memcpy(pstmt_space, pstmt_data, pstmt_len);</span>
<span class="lineNum">     716 </span><span class="lineCov">        174 :     shm_toc_insert(pcxt-&gt;toc, PARALLEL_KEY_PLANNEDSTMT, pstmt_space);</span>
<span class="lineNum">     717 </span>            : 
<span class="lineNum">     718 </span>            :     /* Store serialized ParamListInfo. */
<span class="lineNum">     719 </span><span class="lineCov">        174 :     paramlistinfo_space = shm_toc_allocate(pcxt-&gt;toc, paramlistinfo_len);</span>
<span class="lineNum">     720 </span><span class="lineCov">        174 :     shm_toc_insert(pcxt-&gt;toc, PARALLEL_KEY_PARAMLISTINFO, paramlistinfo_space);</span>
<span class="lineNum">     721 </span><span class="lineCov">        174 :     SerializeParamList(estate-&gt;es_param_list_info, &amp;paramlistinfo_space);</span>
<span class="lineNum">     722 </span>            : 
<span class="lineNum">     723 </span>            :     /* Allocate space for each worker's BufferUsage; no need to initialize. */
<span class="lineNum">     724 </span><span class="lineCov">        174 :     bufusage_space = shm_toc_allocate(pcxt-&gt;toc,</span>
<span class="lineNum">     725 </span><span class="lineCov">        174 :                                       mul_size(sizeof(BufferUsage), pcxt-&gt;nworkers));</span>
<span class="lineNum">     726 </span><span class="lineCov">        174 :     shm_toc_insert(pcxt-&gt;toc, PARALLEL_KEY_BUFFER_USAGE, bufusage_space);</span>
<span class="lineNum">     727 </span><span class="lineCov">        174 :     pei-&gt;buffer_usage = bufusage_space;</span>
<span class="lineNum">     728 </span>            : 
<span class="lineNum">     729 </span>            :     /* Set up the tuple queues that the workers will write into. */
<span class="lineNum">     730 </span><span class="lineCov">        174 :     pei-&gt;tqueue = ExecParallelSetupTupleQueues(pcxt, false);</span>
<span class="lineNum">     731 </span>            : 
<span class="lineNum">     732 </span>            :     /* We don't need the TupleQueueReaders yet, though. */
<span class="lineNum">     733 </span><span class="lineCov">        174 :     pei-&gt;reader = NULL;</span>
<span class="lineNum">     734 </span>            : 
<span class="lineNum">     735 </span>            :     /*
<span class="lineNum">     736 </span>            :      * If instrumentation options were supplied, allocate space for the data.
<span class="lineNum">     737 </span>            :      * It only gets partially initialized here; the rest happens during
<span class="lineNum">     738 </span>            :      * ExecParallelInitializeDSM.
<span class="lineNum">     739 </span>            :      */
<span class="lineNum">     740 </span><span class="lineCov">        174 :     if (estate-&gt;es_instrument)</span>
<span class="lineNum">     741 </span>            :     {
<span class="lineNum">     742 </span>            :         Instrumentation *instrument;
<span class="lineNum">     743 </span>            :         int         i;
<span class="lineNum">     744 </span>            : 
<span class="lineNum">     745 </span><span class="lineCov">         54 :         instrumentation = shm_toc_allocate(pcxt-&gt;toc, instrumentation_len);</span>
<span class="lineNum">     746 </span><span class="lineCov">         54 :         instrumentation-&gt;instrument_options = estate-&gt;es_instrument;</span>
<span class="lineNum">     747 </span><span class="lineCov">         54 :         instrumentation-&gt;instrument_offset = instrument_offset;</span>
<span class="lineNum">     748 </span><span class="lineCov">         54 :         instrumentation-&gt;num_workers = nworkers;</span>
<span class="lineNum">     749 </span><span class="lineCov">         54 :         instrumentation-&gt;num_plan_nodes = e.nnodes;</span>
<span class="lineNum">     750 </span><span class="lineCov">         54 :         instrument = GetInstrumentationArray(instrumentation);</span>
<span class="lineNum">     751 </span><span class="lineCov">        556 :         for (i = 0; i &lt; nworkers * e.nnodes; ++i)</span>
<span class="lineNum">     752 </span><span class="lineCov">        502 :             InstrInit(&amp;instrument[i], estate-&gt;es_instrument);</span>
<span class="lineNum">     753 </span><span class="lineCov">         54 :         shm_toc_insert(pcxt-&gt;toc, PARALLEL_KEY_INSTRUMENTATION,</span>
<span class="lineNum">     754 </span>            :                        instrumentation);
<span class="lineNum">     755 </span><span class="lineCov">         54 :         pei-&gt;instrumentation = instrumentation;</span>
<span class="lineNum">     756 </span>            : 
<span class="lineNum">     757 </span><span class="lineCov">         54 :         if (estate-&gt;es_jit_flags != PGJIT_NONE)</span>
<span class="lineNum">     758 </span>            :         {
<span class="lineNum">     759 </span><span class="lineCov">          8 :             jit_instrumentation = shm_toc_allocate(pcxt-&gt;toc,</span>
<span class="lineNum">     760 </span>            :                                                    jit_instrumentation_len);
<span class="lineNum">     761 </span><span class="lineCov">          8 :             jit_instrumentation-&gt;num_workers = nworkers;</span>
<span class="lineNum">     762 </span><span class="lineCov">          8 :             memset(jit_instrumentation-&gt;jit_instr, 0,</span>
<span class="lineNum">     763 </span>            :                    sizeof(JitInstrumentation) * nworkers);
<span class="lineNum">     764 </span><span class="lineCov">          8 :             shm_toc_insert(pcxt-&gt;toc, PARALLEL_KEY_JIT_INSTRUMENTATION,</span>
<span class="lineNum">     765 </span>            :                            jit_instrumentation);
<span class="lineNum">     766 </span><span class="lineCov">          8 :             pei-&gt;jit_instrumentation = jit_instrumentation;</span>
<span class="lineNum">     767 </span>            :         }
<span class="lineNum">     768 </span>            :     }
<span class="lineNum">     769 </span>            : 
<span class="lineNum">     770 </span>            :     /*
<span class="lineNum">     771 </span>            :      * Create a DSA area that can be used by the leader and all workers.
<span class="lineNum">     772 </span>            :      * (However, if we failed to create a DSM and are using private memory
<span class="lineNum">     773 </span>            :      * instead, then skip this.)
<span class="lineNum">     774 </span>            :      */
<span class="lineNum">     775 </span><span class="lineCov">        174 :     if (pcxt-&gt;seg != NULL)</span>
<span class="lineNum">     776 </span>            :     {
<span class="lineNum">     777 </span>            :         char       *area_space;
<span class="lineNum">     778 </span>            : 
<span class="lineNum">     779 </span><span class="lineCov">        174 :         area_space = shm_toc_allocate(pcxt-&gt;toc, dsa_minsize);</span>
<span class="lineNum">     780 </span><span class="lineCov">        174 :         shm_toc_insert(pcxt-&gt;toc, PARALLEL_KEY_DSA, area_space);</span>
<span class="lineNum">     781 </span><span class="lineCov">        174 :         pei-&gt;area = dsa_create_in_place(area_space, dsa_minsize,</span>
<span class="lineNum">     782 </span>            :                                         LWTRANCHE_PARALLEL_QUERY_DSA,
<span class="lineNum">     783 </span>            :                                         pcxt-&gt;seg);
<span class="lineNum">     784 </span>            : 
<span class="lineNum">     785 </span>            :         /*
<span class="lineNum">     786 </span>            :          * Serialize parameters, if any, using DSA storage.  We don't dare use
<span class="lineNum">     787 </span>            :          * the main parallel query DSM for this because we might relaunch
<span class="lineNum">     788 </span>            :          * workers after the values have changed (and thus the amount of
<span class="lineNum">     789 </span>            :          * storage required has changed).
<span class="lineNum">     790 </span>            :          */
<span class="lineNum">     791 </span><span class="lineCov">        174 :         if (!bms_is_empty(sendParams))</span>
<span class="lineNum">     792 </span>            :         {
<span class="lineNum">     793 </span><span class="lineCov">          4 :             pei-&gt;param_exec = SerializeParamExecParams(estate, sendParams,</span>
<span class="lineNum">     794 </span>            :                                                        pei-&gt;area);
<span class="lineNum">     795 </span><span class="lineCov">          4 :             fpes-&gt;param_exec = pei-&gt;param_exec;</span>
<span class="lineNum">     796 </span>            :         }
<span class="lineNum">     797 </span>            :     }
<span class="lineNum">     798 </span>            : 
<span class="lineNum">     799 </span>            :     /*
<span class="lineNum">     800 </span>            :      * Give parallel-aware nodes a chance to initialize their shared data.
<span class="lineNum">     801 </span>            :      * This also initializes the elements of instrumentation-&gt;ps_instrument,
<span class="lineNum">     802 </span>            :      * if it exists.
<span class="lineNum">     803 </span>            :      */
<span class="lineNum">     804 </span><span class="lineCov">        174 :     d.pcxt = pcxt;</span>
<span class="lineNum">     805 </span><span class="lineCov">        174 :     d.instrumentation = instrumentation;</span>
<span class="lineNum">     806 </span><span class="lineCov">        174 :     d.nnodes = 0;</span>
<span class="lineNum">     807 </span>            : 
<span class="lineNum">     808 </span>            :     /* Install our DSA area while initializing the plan. */
<span class="lineNum">     809 </span><span class="lineCov">        174 :     estate-&gt;es_query_dsa = pei-&gt;area;</span>
<span class="lineNum">     810 </span><span class="lineCov">        174 :     ExecParallelInitializeDSM(planstate, &amp;d);</span>
<span class="lineNum">     811 </span><span class="lineCov">        174 :     estate-&gt;es_query_dsa = NULL;</span>
<span class="lineNum">     812 </span>            : 
<span class="lineNum">     813 </span>            :     /*
<span class="lineNum">     814 </span>            :      * Make sure that the world hasn't shifted under our feet.  This could
<span class="lineNum">     815 </span>            :      * probably just be an Assert(), but let's be conservative for now.
<span class="lineNum">     816 </span>            :      */
<span class="lineNum">     817 </span><span class="lineCov">        174 :     if (e.nnodes != d.nnodes)</span>
<span class="lineNum">     818 </span><span class="lineNoCov">          0 :         elog(ERROR, &quot;inconsistent count of PlanState nodes&quot;);</span>
<span class="lineNum">     819 </span>            : 
<span class="lineNum">     820 </span>            :     /* OK, we're ready to rock and roll. */
<span class="lineNum">     821 </span><span class="lineCov">        174 :     return pei;</span>
<span class="lineNum">     822 </span>            : }
<span class="lineNum">     823 </span>            : 
<span class="lineNum">     824 </span>            : /*
<span class="lineNum">     825 </span>            :  * Set up tuple queue readers to read the results of a parallel subplan.
<span class="lineNum">     826 </span>            :  *
<span class="lineNum">     827 </span>            :  * This is separate from ExecInitParallelPlan() because we can launch the
<span class="lineNum">     828 </span>            :  * worker processes and let them start doing something before we do this.
<a name="829"><span class="lineNum">     829 </span>            :  */</a>
<span class="lineNum">     830 </span>            : void
<span class="lineNum">     831 </span><span class="lineCov">        252 : ExecParallelCreateReaders(ParallelExecutorInfo *pei)</span>
<span class="lineNum">     832 </span>            : {
<span class="lineNum">     833 </span><span class="lineCov">        252 :     int         nworkers = pei-&gt;pcxt-&gt;nworkers_launched;</span>
<span class="lineNum">     834 </span>            :     int         i;
<span class="lineNum">     835 </span>            : 
<span class="lineNum">     836 </span><span class="lineCov">        252 :     Assert(pei-&gt;reader == NULL);</span>
<span class="lineNum">     837 </span>            : 
<span class="lineNum">     838 </span><span class="lineCov">        252 :     if (nworkers &gt; 0)</span>
<span class="lineNum">     839 </span>            :     {
<span class="lineNum">     840 </span><span class="lineCov">        252 :         pei-&gt;reader = (TupleQueueReader **)</span>
<span class="lineNum">     841 </span><span class="lineCov">        252 :             palloc(nworkers * sizeof(TupleQueueReader *));</span>
<span class="lineNum">     842 </span>            : 
<span class="lineNum">     843 </span><span class="lineCov">        958 :         for (i = 0; i &lt; nworkers; i++)</span>
<span class="lineNum">     844 </span>            :         {
<span class="lineNum">     845 </span><span class="lineCov">        706 :             shm_mq_set_handle(pei-&gt;tqueue[i],</span>
<span class="lineNum">     846 </span><span class="lineCov">        706 :                               pei-&gt;pcxt-&gt;worker[i].bgwhandle);</span>
<span class="lineNum">     847 </span><span class="lineCov">        706 :             pei-&gt;reader[i] = CreateTupleQueueReader(pei-&gt;tqueue[i]);</span>
<span class="lineNum">     848 </span>            :         }
<span class="lineNum">     849 </span>            :     }
<span class="lineNum">     850 </span><span class="lineCov">        252 : }</span>
<span class="lineNum">     851 </span>            : 
<span class="lineNum">     852 </span>            : /*
<span class="lineNum">     853 </span>            :  * Re-initialize the parallel executor shared memory state before launching
<span class="lineNum">     854 </span>            :  * a fresh batch of workers.
<a name="855"><span class="lineNum">     855 </span>            :  */</a>
<span class="lineNum">     856 </span>            : void
<span class="lineNum">     857 </span><span class="lineCov">         84 : ExecParallelReinitialize(PlanState *planstate,</span>
<span class="lineNum">     858 </span>            :                          ParallelExecutorInfo *pei,
<span class="lineNum">     859 </span>            :                          Bitmapset *sendParams)
<span class="lineNum">     860 </span>            : {
<span class="lineNum">     861 </span><span class="lineCov">         84 :     EState     *estate = planstate-&gt;state;</span>
<span class="lineNum">     862 </span>            :     FixedParallelExecutorState *fpes;
<span class="lineNum">     863 </span>            : 
<span class="lineNum">     864 </span>            :     /* Old workers must already be shut down */
<span class="lineNum">     865 </span><span class="lineCov">         84 :     Assert(pei-&gt;finished);</span>
<span class="lineNum">     866 </span>            : 
<span class="lineNum">     867 </span>            :     /*
<span class="lineNum">     868 </span>            :      * Force any initplan outputs that we're going to pass to workers to be
<span class="lineNum">     869 </span>            :      * evaluated, if they weren't already (see comments in
<span class="lineNum">     870 </span>            :      * ExecInitParallelPlan).
<span class="lineNum">     871 </span>            :      */
<span class="lineNum">     872 </span><span class="lineCov">         84 :     ExecSetParamPlanMulti(sendParams, GetPerTupleExprContext(estate));</span>
<span class="lineNum">     873 </span>            : 
<span class="lineNum">     874 </span><span class="lineCov">         84 :     ReinitializeParallelDSM(pei-&gt;pcxt);</span>
<span class="lineNum">     875 </span><span class="lineCov">         84 :     pei-&gt;tqueue = ExecParallelSetupTupleQueues(pei-&gt;pcxt, true);</span>
<span class="lineNum">     876 </span><span class="lineCov">         84 :     pei-&gt;reader = NULL;</span>
<span class="lineNum">     877 </span><span class="lineCov">         84 :     pei-&gt;finished = false;</span>
<span class="lineNum">     878 </span>            : 
<span class="lineNum">     879 </span><span class="lineCov">         84 :     fpes = shm_toc_lookup(pei-&gt;pcxt-&gt;toc, PARALLEL_KEY_EXECUTOR_FIXED, false);</span>
<span class="lineNum">     880 </span>            : 
<span class="lineNum">     881 </span>            :     /* Free any serialized parameters from the last round. */
<span class="lineNum">     882 </span><span class="lineCov">         84 :     if (DsaPointerIsValid(fpes-&gt;param_exec))</span>
<span class="lineNum">     883 </span>            :     {
<span class="lineNum">     884 </span><span class="lineNoCov">          0 :         dsa_free(pei-&gt;area, fpes-&gt;param_exec);</span>
<span class="lineNum">     885 </span><span class="lineNoCov">          0 :         fpes-&gt;param_exec = InvalidDsaPointer;</span>
<span class="lineNum">     886 </span>            :     }
<span class="lineNum">     887 </span>            : 
<span class="lineNum">     888 </span>            :     /* Serialize current parameter values if required. */
<span class="lineNum">     889 </span><span class="lineCov">         84 :     if (!bms_is_empty(sendParams))</span>
<span class="lineNum">     890 </span>            :     {
<span class="lineNum">     891 </span><span class="lineNoCov">          0 :         pei-&gt;param_exec = SerializeParamExecParams(estate, sendParams,</span>
<span class="lineNum">     892 </span>            :                                                    pei-&gt;area);
<span class="lineNum">     893 </span><span class="lineNoCov">          0 :         fpes-&gt;param_exec = pei-&gt;param_exec;</span>
<span class="lineNum">     894 </span>            :     }
<span class="lineNum">     895 </span>            : 
<span class="lineNum">     896 </span>            :     /* Traverse plan tree and let each child node reset associated state. */
<span class="lineNum">     897 </span><span class="lineCov">         84 :     estate-&gt;es_query_dsa = pei-&gt;area;</span>
<span class="lineNum">     898 </span><span class="lineCov">         84 :     ExecParallelReInitializeDSM(planstate, pei-&gt;pcxt);</span>
<span class="lineNum">     899 </span><span class="lineCov">         84 :     estate-&gt;es_query_dsa = NULL;</span>
<span class="lineNum">     900 </span><span class="lineCov">         84 : }</span>
<span class="lineNum">     901 </span>            : 
<span class="lineNum">     902 </span>            : /*
<span class="lineNum">     903 </span>            :  * Traverse plan tree to reinitialize per-node dynamic shared memory state
<a name="904"><span class="lineNum">     904 </span>            :  */</a>
<span class="lineNum">     905 </span>            : static bool
<span class="lineNum">     906 </span><span class="lineCov">        218 : ExecParallelReInitializeDSM(PlanState *planstate,</span>
<span class="lineNum">     907 </span>            :                             ParallelContext *pcxt)
<span class="lineNum">     908 </span>            : {
<span class="lineNum">     909 </span><span class="lineCov">        218 :     if (planstate == NULL)</span>
<span class="lineNum">     910 </span><span class="lineNoCov">          0 :         return false;</span>
<span class="lineNum">     911 </span>            : 
<span class="lineNum">     912 </span>            :     /*
<span class="lineNum">     913 </span>            :      * Call reinitializers for DSM-using plan nodes.
<span class="lineNum">     914 </span>            :      */
<span class="lineNum">     915 </span><span class="lineCov">        218 :     switch (nodeTag(planstate))</span>
<span class="lineNum">     916 </span>            :     {
<span class="lineNum">     917 </span>            :         case T_SeqScanState:
<span class="lineNum">     918 </span><span class="lineCov">         90 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     919 </span><span class="lineCov">         74 :                 ExecSeqScanReInitializeDSM((SeqScanState *) planstate,</span>
<span class="lineNum">     920 </span>            :                                            pcxt);
<span class="lineNum">     921 </span><span class="lineCov">         90 :             break;</span>
<span class="lineNum">     922 </span>            :         case T_IndexScanState:
<span class="lineNum">     923 </span><span class="lineCov">          4 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     924 </span><span class="lineCov">          4 :                 ExecIndexScanReInitializeDSM((IndexScanState *) planstate,</span>
<span class="lineNum">     925 </span>            :                                              pcxt);
<span class="lineNum">     926 </span><span class="lineCov">          4 :             break;</span>
<span class="lineNum">     927 </span>            :         case T_IndexOnlyScanState:
<span class="lineNum">     928 </span><span class="lineCov">          4 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     929 </span><span class="lineCov">          4 :                 ExecIndexOnlyScanReInitializeDSM((IndexOnlyScanState *) planstate,</span>
<span class="lineNum">     930 </span>            :                                                  pcxt);
<span class="lineNum">     931 </span><span class="lineCov">          4 :             break;</span>
<span class="lineNum">     932 </span>            :         case T_ForeignScanState:
<span class="lineNum">     933 </span><span class="lineNoCov">          0 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     934 </span><span class="lineNoCov">          0 :                 ExecForeignScanReInitializeDSM((ForeignScanState *) planstate,</span>
<span class="lineNum">     935 </span>            :                                                pcxt);
<span class="lineNum">     936 </span><span class="lineNoCov">          0 :             break;</span>
<span class="lineNum">     937 </span>            :         case T_AppendState:
<span class="lineNum">     938 </span><span class="lineNoCov">          0 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     939 </span><span class="lineNoCov">          0 :                 ExecAppendReInitializeDSM((AppendState *) planstate, pcxt);</span>
<span class="lineNum">     940 </span><span class="lineNoCov">          0 :             break;</span>
<span class="lineNum">     941 </span>            :         case T_CustomScanState:
<span class="lineNum">     942 </span><span class="lineNoCov">          0 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     943 </span><span class="lineNoCov">          0 :                 ExecCustomScanReInitializeDSM((CustomScanState *) planstate,</span>
<span class="lineNum">     944 </span>            :                                               pcxt);
<span class="lineNum">     945 </span><span class="lineNoCov">          0 :             break;</span>
<span class="lineNum">     946 </span>            :         case T_BitmapHeapScanState:
<span class="lineNum">     947 </span><span class="lineCov">         18 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     948 </span><span class="lineCov">         18 :                 ExecBitmapHeapReInitializeDSM((BitmapHeapScanState *) planstate,</span>
<span class="lineNum">     949 </span>            :                                               pcxt);
<span class="lineNum">     950 </span><span class="lineCov">         18 :             break;</span>
<span class="lineNum">     951 </span>            :         case T_HashJoinState:
<span class="lineNum">     952 </span><span class="lineCov">         32 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">     953 </span><span class="lineCov">         16 :                 ExecHashJoinReInitializeDSM((HashJoinState *) planstate,</span>
<span class="lineNum">     954 </span>            :                                             pcxt);
<span class="lineNum">     955 </span><span class="lineCov">         32 :             break;</span>
<span class="lineNum">     956 </span>            :         case T_HashState:
<span class="lineNum">     957 </span>            :         case T_SortState:
<span class="lineNum">     958 </span>            :             /* these nodes have DSM state, but no reinitialization is required */
<span class="lineNum">     959 </span><span class="lineCov">         40 :             break;</span>
<span class="lineNum">     960 </span>            : 
<span class="lineNum">     961 </span>            :         default:
<span class="lineNum">     962 </span><span class="lineCov">         30 :             break;</span>
<span class="lineNum">     963 </span>            :     }
<span class="lineNum">     964 </span>            : 
<span class="lineNum">     965 </span><span class="lineCov">        218 :     return planstate_tree_walker(planstate, ExecParallelReInitializeDSM, pcxt);</span>
<span class="lineNum">     966 </span>            : }
<span class="lineNum">     967 </span>            : 
<span class="lineNum">     968 </span>            : /*
<span class="lineNum">     969 </span>            :  * Copy instrumentation information about this node and its descendants from
<span class="lineNum">     970 </span>            :  * dynamic shared memory.
<a name="971"><span class="lineNum">     971 </span>            :  */</a>
<span class="lineNum">     972 </span>            : static bool
<span class="lineNum">     973 </span><span class="lineCov">        318 : ExecParallelRetrieveInstrumentation(PlanState *planstate,</span>
<span class="lineNum">     974 </span>            :                                     SharedExecutorInstrumentation *instrumentation)
<span class="lineNum">     975 </span>            : {
<span class="lineNum">     976 </span>            :     Instrumentation *instrument;
<span class="lineNum">     977 </span>            :     int         i;
<span class="lineNum">     978 </span>            :     int         n;
<span class="lineNum">     979 </span>            :     int         ibytes;
<span class="lineNum">     980 </span><span class="lineCov">        318 :     int         plan_node_id = planstate-&gt;plan-&gt;plan_node_id;</span>
<span class="lineNum">     981 </span>            :     MemoryContext oldcontext;
<span class="lineNum">     982 </span>            : 
<span class="lineNum">     983 </span>            :     /* Find the instrumentation for this node. */
<span class="lineNum">     984 </span><span class="lineCov">       1454 :     for (i = 0; i &lt; instrumentation-&gt;num_plan_nodes; ++i)</span>
<span class="lineNum">     985 </span><span class="lineCov">       1454 :         if (instrumentation-&gt;plan_node_id[i] == plan_node_id)</span>
<span class="lineNum">     986 </span><span class="lineCov">        318 :             break;</span>
<span class="lineNum">     987 </span><span class="lineCov">        318 :     if (i &gt;= instrumentation-&gt;num_plan_nodes)</span>
<span class="lineNum">     988 </span><span class="lineNoCov">          0 :         elog(ERROR, &quot;plan node %d not found&quot;, plan_node_id);</span>
<span class="lineNum">     989 </span>            : 
<span class="lineNum">     990 </span>            :     /* Accumulate the statistics from all workers. */
<span class="lineNum">     991 </span><span class="lineCov">        318 :     instrument = GetInstrumentationArray(instrumentation);</span>
<span class="lineNum">     992 </span><span class="lineCov">        318 :     instrument += i * instrumentation-&gt;num_workers;</span>
<span class="lineNum">     993 </span><span class="lineCov">        820 :     for (n = 0; n &lt; instrumentation-&gt;num_workers; ++n)</span>
<span class="lineNum">     994 </span><span class="lineCov">        502 :         InstrAggNode(planstate-&gt;instrument, &amp;instrument[n]);</span>
<span class="lineNum">     995 </span>            : 
<span class="lineNum">     996 </span>            :     /*
<span class="lineNum">     997 </span>            :      * Also store the per-worker detail.
<span class="lineNum">     998 </span>            :      *
<span class="lineNum">     999 </span>            :      * Worker instrumentation should be allocated in the same context as the
<span class="lineNum">    1000 </span>            :      * regular instrumentation information, which is the per-query context.
<span class="lineNum">    1001 </span>            :      * Switch into per-query memory context.
<span class="lineNum">    1002 </span>            :      */
<span class="lineNum">    1003 </span><span class="lineCov">        318 :     oldcontext = MemoryContextSwitchTo(planstate-&gt;state-&gt;es_query_cxt);</span>
<span class="lineNum">    1004 </span><span class="lineCov">        318 :     ibytes = mul_size(instrumentation-&gt;num_workers, sizeof(Instrumentation));</span>
<span class="lineNum">    1005 </span><span class="lineCov">        318 :     planstate-&gt;worker_instrument =</span>
<span class="lineNum">    1006 </span><span class="lineCov">        318 :         palloc(ibytes + offsetof(WorkerInstrumentation, instrument));</span>
<span class="lineNum">    1007 </span><span class="lineCov">        318 :     MemoryContextSwitchTo(oldcontext);</span>
<span class="lineNum">    1008 </span>            : 
<span class="lineNum">    1009 </span><span class="lineCov">        318 :     planstate-&gt;worker_instrument-&gt;num_workers = instrumentation-&gt;num_workers;</span>
<span class="lineNum">    1010 </span><span class="lineCov">        318 :     memcpy(&amp;planstate-&gt;worker_instrument-&gt;instrument, instrument, ibytes);</span>
<span class="lineNum">    1011 </span>            : 
<span class="lineNum">    1012 </span>            :     /* Perform any node-type-specific work that needs to be done. */
<span class="lineNum">    1013 </span><span class="lineCov">        318 :     switch (nodeTag(planstate))</span>
<span class="lineNum">    1014 </span>            :     {
<span class="lineNum">    1015 </span>            :         case T_SortState:
<span class="lineNum">    1016 </span><span class="lineCov">          2 :             ExecSortRetrieveInstrumentation((SortState *) planstate);</span>
<span class="lineNum">    1017 </span><span class="lineCov">          2 :             break;</span>
<span class="lineNum">    1018 </span>            :         case T_HashState:
<span class="lineNum">    1019 </span><span class="lineCov">         28 :             ExecHashRetrieveInstrumentation((HashState *) planstate);</span>
<span class="lineNum">    1020 </span><span class="lineCov">         28 :             break;</span>
<span class="lineNum">    1021 </span>            :         default:
<span class="lineNum">    1022 </span><span class="lineCov">        288 :             break;</span>
<span class="lineNum">    1023 </span>            :     }
<span class="lineNum">    1024 </span>            : 
<span class="lineNum">    1025 </span><span class="lineCov">        318 :     return planstate_tree_walker(planstate, ExecParallelRetrieveInstrumentation,</span>
<span class="lineNum">    1026 </span>            :                                  instrumentation);
<span class="lineNum">    1027 </span>            : }
<span class="lineNum">    1028 </span>            : 
<span class="lineNum">    1029 </span>            : /*
<span class="lineNum">    1030 </span>            :  * Add up the workers' JIT instrumentation from dynamic shared memory.
<a name="1031"><span class="lineNum">    1031 </span>            :  */</a>
<span class="lineNum">    1032 </span>            : static void
<span class="lineNum">    1033 </span><span class="lineCov">          8 : ExecParallelRetrieveJitInstrumentation(PlanState *planstate,</span>
<span class="lineNum">    1034 </span>            :                                        SharedJitInstrumentation *shared_jit)
<span class="lineNum">    1035 </span>            : {
<span class="lineNum">    1036 </span>            :     JitInstrumentation *combined;
<span class="lineNum">    1037 </span>            :     int         ibytes;
<span class="lineNum">    1038 </span>            : 
<span class="lineNum">    1039 </span>            :     int         n;
<span class="lineNum">    1040 </span>            : 
<span class="lineNum">    1041 </span>            :     /*
<span class="lineNum">    1042 </span>            :      * Accumulate worker JIT instrumentation into the combined JIT
<span class="lineNum">    1043 </span>            :      * instrumentation, allocating it if required.
<span class="lineNum">    1044 </span>            :      */
<span class="lineNum">    1045 </span><span class="lineCov">          8 :     if (!planstate-&gt;state-&gt;es_jit_worker_instr)</span>
<span class="lineNum">    1046 </span><span class="lineCov">         16 :         planstate-&gt;state-&gt;es_jit_worker_instr =</span>
<span class="lineNum">    1047 </span><span class="lineCov">          8 :             MemoryContextAllocZero(planstate-&gt;state-&gt;es_query_cxt, sizeof(JitInstrumentation));</span>
<span class="lineNum">    1048 </span><span class="lineCov">          8 :     combined = planstate-&gt;state-&gt;es_jit_worker_instr;</span>
<span class="lineNum">    1049 </span>            : 
<span class="lineNum">    1050 </span>            :     /* Accumulate all the workers' instrumentations. */
<span class="lineNum">    1051 </span><span class="lineCov">         24 :     for (n = 0; n &lt; shared_jit-&gt;num_workers; ++n)</span>
<span class="lineNum">    1052 </span><span class="lineCov">         16 :         InstrJitAgg(combined, &amp;shared_jit-&gt;jit_instr[n]);</span>
<span class="lineNum">    1053 </span>            : 
<span class="lineNum">    1054 </span>            :     /*
<span class="lineNum">    1055 </span>            :      * Store the per-worker detail.
<span class="lineNum">    1056 </span>            :      *
<span class="lineNum">    1057 </span>            :      * Similar to ExecParallelRetrieveInstrumentation(), allocate the
<span class="lineNum">    1058 </span>            :      * instrumentation in per-query context.
<span class="lineNum">    1059 </span>            :      */
<span class="lineNum">    1060 </span><span class="lineCov">          8 :     ibytes = offsetof(SharedJitInstrumentation, jit_instr)</span>
<span class="lineNum">    1061 </span><span class="lineCov">          8 :         + mul_size(shared_jit-&gt;num_workers, sizeof(JitInstrumentation));</span>
<span class="lineNum">    1062 </span><span class="lineCov">          8 :     planstate-&gt;worker_jit_instrument =</span>
<span class="lineNum">    1063 </span><span class="lineCov">          8 :         MemoryContextAlloc(planstate-&gt;state-&gt;es_query_cxt, ibytes);</span>
<span class="lineNum">    1064 </span>            : 
<span class="lineNum">    1065 </span><span class="lineCov">          8 :     memcpy(planstate-&gt;worker_jit_instrument, shared_jit, ibytes);</span>
<span class="lineNum">    1066 </span><span class="lineCov">          8 : }</span>
<span class="lineNum">    1067 </span>            : 
<span class="lineNum">    1068 </span>            : /*
<span class="lineNum">    1069 </span>            :  * Finish parallel execution.  We wait for parallel workers to finish, and
<span class="lineNum">    1070 </span>            :  * accumulate their buffer usage.
<a name="1071"><span class="lineNum">    1071 </span>            :  */</a>
<span class="lineNum">    1072 </span>            : void
<span class="lineNum">    1073 </span><span class="lineCov">        468 : ExecParallelFinish(ParallelExecutorInfo *pei)</span>
<span class="lineNum">    1074 </span>            : {
<span class="lineNum">    1075 </span><span class="lineCov">        468 :     int         nworkers = pei-&gt;pcxt-&gt;nworkers_launched;</span>
<span class="lineNum">    1076 </span>            :     int         i;
<span class="lineNum">    1077 </span>            : 
<span class="lineNum">    1078 </span>            :     /* Make this be a no-op if called twice in a row. */
<span class="lineNum">    1079 </span><span class="lineCov">        468 :     if (pei-&gt;finished)</span>
<span class="lineNum">    1080 </span><span class="lineCov">        680 :         return;</span>
<span class="lineNum">    1081 </span>            : 
<span class="lineNum">    1082 </span>            :     /*
<span class="lineNum">    1083 </span>            :      * Detach from tuple queues ASAP, so that any still-active workers will
<span class="lineNum">    1084 </span>            :      * notice that no further results are wanted.
<span class="lineNum">    1085 </span>            :      */
<span class="lineNum">    1086 </span><span class="lineCov">        256 :     if (pei-&gt;tqueue != NULL)</span>
<span class="lineNum">    1087 </span>            :     {
<span class="lineNum">    1088 </span><span class="lineCov">        960 :         for (i = 0; i &lt; nworkers; i++)</span>
<span class="lineNum">    1089 </span><span class="lineCov">        704 :             shm_mq_detach(pei-&gt;tqueue[i]);</span>
<span class="lineNum">    1090 </span><span class="lineCov">        256 :         pfree(pei-&gt;tqueue);</span>
<span class="lineNum">    1091 </span><span class="lineCov">        256 :         pei-&gt;tqueue = NULL;</span>
<span class="lineNum">    1092 </span>            :     }
<span class="lineNum">    1093 </span>            : 
<span class="lineNum">    1094 </span>            :     /*
<span class="lineNum">    1095 </span>            :      * While we're waiting for the workers to finish, let's get rid of the
<span class="lineNum">    1096 </span>            :      * tuple queue readers.  (Any other local cleanup could be done here too.)
<span class="lineNum">    1097 </span>            :      */
<span class="lineNum">    1098 </span><span class="lineCov">        256 :     if (pei-&gt;reader != NULL)</span>
<span class="lineNum">    1099 </span>            :     {
<span class="lineNum">    1100 </span><span class="lineCov">        954 :         for (i = 0; i &lt; nworkers; i++)</span>
<span class="lineNum">    1101 </span><span class="lineCov">        704 :             DestroyTupleQueueReader(pei-&gt;reader[i]);</span>
<span class="lineNum">    1102 </span><span class="lineCov">        250 :         pfree(pei-&gt;reader);</span>
<span class="lineNum">    1103 </span><span class="lineCov">        250 :         pei-&gt;reader = NULL;</span>
<span class="lineNum">    1104 </span>            :     }
<span class="lineNum">    1105 </span>            : 
<span class="lineNum">    1106 </span>            :     /* Now wait for the workers to finish. */
<span class="lineNum">    1107 </span><span class="lineCov">        256 :     WaitForParallelWorkersToFinish(pei-&gt;pcxt);</span>
<span class="lineNum">    1108 </span>            : 
<span class="lineNum">    1109 </span>            :     /*
<span class="lineNum">    1110 </span>            :      * Next, accumulate buffer usage.  (This must wait for the workers to
<span class="lineNum">    1111 </span>            :      * finish, or we might get incomplete data.)
<span class="lineNum">    1112 </span>            :      */
<span class="lineNum">    1113 </span><span class="lineCov">        960 :     for (i = 0; i &lt; nworkers; i++)</span>
<span class="lineNum">    1114 </span><span class="lineCov">        704 :         InstrAccumParallelQuery(&amp;pei-&gt;buffer_usage[i]);</span>
<span class="lineNum">    1115 </span>            : 
<span class="lineNum">    1116 </span><span class="lineCov">        256 :     pei-&gt;finished = true;</span>
<span class="lineNum">    1117 </span>            : }
<span class="lineNum">    1118 </span>            : 
<span class="lineNum">    1119 </span>            : /*
<span class="lineNum">    1120 </span>            :  * Accumulate instrumentation, and then clean up whatever ParallelExecutorInfo
<span class="lineNum">    1121 </span>            :  * resources still exist after ExecParallelFinish.  We separate these
<span class="lineNum">    1122 </span>            :  * routines because someone might want to examine the contents of the DSM
<span class="lineNum">    1123 </span>            :  * after ExecParallelFinish and before calling this routine.
<a name="1124"><span class="lineNum">    1124 </span>            :  */</a>
<span class="lineNum">    1125 </span>            : void
<span class="lineNum">    1126 </span><span class="lineCov">        172 : ExecParallelCleanup(ParallelExecutorInfo *pei)</span>
<span class="lineNum">    1127 </span>            : {
<span class="lineNum">    1128 </span>            :     /* Accumulate instrumentation, if any. */
<span class="lineNum">    1129 </span><span class="lineCov">        172 :     if (pei-&gt;instrumentation)</span>
<span class="lineNum">    1130 </span><span class="lineCov">         54 :         ExecParallelRetrieveInstrumentation(pei-&gt;planstate,</span>
<span class="lineNum">    1131 </span>            :                                             pei-&gt;instrumentation);
<span class="lineNum">    1132 </span>            : 
<span class="lineNum">    1133 </span>            :     /* Accumulate JIT instrumentation, if any. */
<span class="lineNum">    1134 </span><span class="lineCov">        172 :     if (pei-&gt;jit_instrumentation)</span>
<span class="lineNum">    1135 </span><span class="lineCov">          8 :         ExecParallelRetrieveJitInstrumentation(pei-&gt;planstate,</span>
<span class="lineNum">    1136 </span><span class="lineCov">          8 :                                                pei-&gt;jit_instrumentation);</span>
<span class="lineNum">    1137 </span>            : 
<span class="lineNum">    1138 </span>            :     /* Free any serialized parameters. */
<span class="lineNum">    1139 </span><span class="lineCov">        172 :     if (DsaPointerIsValid(pei-&gt;param_exec))</span>
<span class="lineNum">    1140 </span>            :     {
<span class="lineNum">    1141 </span><span class="lineCov">          4 :         dsa_free(pei-&gt;area, pei-&gt;param_exec);</span>
<span class="lineNum">    1142 </span><span class="lineCov">          4 :         pei-&gt;param_exec = InvalidDsaPointer;</span>
<span class="lineNum">    1143 </span>            :     }
<span class="lineNum">    1144 </span><span class="lineCov">        172 :     if (pei-&gt;area != NULL)</span>
<span class="lineNum">    1145 </span>            :     {
<span class="lineNum">    1146 </span><span class="lineCov">        172 :         dsa_detach(pei-&gt;area);</span>
<span class="lineNum">    1147 </span><span class="lineCov">        172 :         pei-&gt;area = NULL;</span>
<span class="lineNum">    1148 </span>            :     }
<span class="lineNum">    1149 </span><span class="lineCov">        172 :     if (pei-&gt;pcxt != NULL)</span>
<span class="lineNum">    1150 </span>            :     {
<span class="lineNum">    1151 </span><span class="lineCov">        172 :         DestroyParallelContext(pei-&gt;pcxt);</span>
<span class="lineNum">    1152 </span><span class="lineCov">        172 :         pei-&gt;pcxt = NULL;</span>
<span class="lineNum">    1153 </span>            :     }
<span class="lineNum">    1154 </span><span class="lineCov">        172 :     pfree(pei);</span>
<span class="lineNum">    1155 </span><span class="lineCov">        172 : }</span>
<span class="lineNum">    1156 </span>            : 
<span class="lineNum">    1157 </span>            : /*
<span class="lineNum">    1158 </span>            :  * Create a DestReceiver to write tuples we produce to the shm_mq designated
<span class="lineNum">    1159 </span>            :  * for that purpose.
<a name="1160"><span class="lineNum">    1160 </span>            :  */</a>
<span class="lineNum">    1161 </span>            : static DestReceiver *
<span class="lineNum">    1162 </span><span class="lineCov">        706 : ExecParallelGetReceiver(dsm_segment *seg, shm_toc *toc)</span>
<span class="lineNum">    1163 </span>            : {
<span class="lineNum">    1164 </span>            :     char       *mqspace;
<span class="lineNum">    1165 </span>            :     shm_mq     *mq;
<span class="lineNum">    1166 </span>            : 
<span class="lineNum">    1167 </span><span class="lineCov">        706 :     mqspace = shm_toc_lookup(toc, PARALLEL_KEY_TUPLE_QUEUE, false);</span>
<span class="lineNum">    1168 </span><span class="lineCov">        706 :     mqspace += ParallelWorkerNumber * PARALLEL_TUPLE_QUEUE_SIZE;</span>
<span class="lineNum">    1169 </span><span class="lineCov">        706 :     mq = (shm_mq *) mqspace;</span>
<span class="lineNum">    1170 </span><span class="lineCov">        706 :     shm_mq_set_sender(mq, MyProc);</span>
<span class="lineNum">    1171 </span><span class="lineCov">        706 :     return CreateTupleQueueDestReceiver(shm_mq_attach(mq, seg, NULL));</span>
<span class="lineNum">    1172 </span>            : }
<span class="lineNum">    1173 </span>            : 
<span class="lineNum">    1174 </span>            : /*
<span class="lineNum">    1175 </span>            :  * Create a QueryDesc for the PlannedStmt we are to execute, and return it.
<a name="1176"><span class="lineNum">    1176 </span>            :  */</a>
<span class="lineNum">    1177 </span>            : static QueryDesc *
<span class="lineNum">    1178 </span><span class="lineCov">        706 : ExecParallelGetQueryDesc(shm_toc *toc, DestReceiver *receiver,</span>
<span class="lineNum">    1179 </span>            :                          int instrument_options)
<span class="lineNum">    1180 </span>            : {
<span class="lineNum">    1181 </span>            :     char       *pstmtspace;
<span class="lineNum">    1182 </span>            :     char       *paramspace;
<span class="lineNum">    1183 </span>            :     PlannedStmt *pstmt;
<span class="lineNum">    1184 </span>            :     ParamListInfo paramLI;
<span class="lineNum">    1185 </span>            :     char       *queryString;
<span class="lineNum">    1186 </span>            : 
<span class="lineNum">    1187 </span>            :     /* Get the query string from shared memory */
<span class="lineNum">    1188 </span><span class="lineCov">        706 :     queryString = shm_toc_lookup(toc, PARALLEL_KEY_QUERY_TEXT, false);</span>
<span class="lineNum">    1189 </span>            : 
<span class="lineNum">    1190 </span>            :     /* Reconstruct leader-supplied PlannedStmt. */
<span class="lineNum">    1191 </span><span class="lineCov">        706 :     pstmtspace = shm_toc_lookup(toc, PARALLEL_KEY_PLANNEDSTMT, false);</span>
<span class="lineNum">    1192 </span><span class="lineCov">        706 :     pstmt = (PlannedStmt *) stringToNode(pstmtspace);</span>
<span class="lineNum">    1193 </span>            : 
<span class="lineNum">    1194 </span>            :     /* Reconstruct ParamListInfo. */
<span class="lineNum">    1195 </span><span class="lineCov">        706 :     paramspace = shm_toc_lookup(toc, PARALLEL_KEY_PARAMLISTINFO, false);</span>
<span class="lineNum">    1196 </span><span class="lineCov">        706 :     paramLI = RestoreParamList(&amp;paramspace);</span>
<span class="lineNum">    1197 </span>            : 
<span class="lineNum">    1198 </span>            :     /* Create a QueryDesc for the query. */
<span class="lineNum">    1199 </span><span class="lineCov">        706 :     return CreateQueryDesc(pstmt,</span>
<span class="lineNum">    1200 </span>            :                            queryString,
<span class="lineNum">    1201 </span>            :                            GetActiveSnapshot(), InvalidSnapshot,
<span class="lineNum">    1202 </span>            :                            receiver, paramLI, NULL, instrument_options);
<span class="lineNum">    1203 </span>            : }
<span class="lineNum">    1204 </span>            : 
<span class="lineNum">    1205 </span>            : /*
<span class="lineNum">    1206 </span>            :  * Copy instrumentation information from this node and its descendants into
<span class="lineNum">    1207 </span>            :  * dynamic shared memory, so that the parallel leader can retrieve it.
<a name="1208"><span class="lineNum">    1208 </span>            :  */</a>
<span class="lineNum">    1209 </span>            : static bool
<span class="lineNum">    1210 </span><span class="lineCov">        734 : ExecParallelReportInstrumentation(PlanState *planstate,</span>
<span class="lineNum">    1211 </span>            :                                   SharedExecutorInstrumentation *instrumentation)
<span class="lineNum">    1212 </span>            : {
<span class="lineNum">    1213 </span>            :     int         i;
<span class="lineNum">    1214 </span><span class="lineCov">        734 :     int         plan_node_id = planstate-&gt;plan-&gt;plan_node_id;</span>
<span class="lineNum">    1215 </span>            :     Instrumentation *instrument;
<span class="lineNum">    1216 </span>            : 
<span class="lineNum">    1217 </span><span class="lineCov">        734 :     InstrEndLoop(planstate-&gt;instrument);</span>
<span class="lineNum">    1218 </span>            : 
<span class="lineNum">    1219 </span>            :     /*
<span class="lineNum">    1220 </span>            :      * If we shuffled the plan_node_id values in ps_instrument into sorted
<span class="lineNum">    1221 </span>            :      * order, we could use binary search here.  This might matter someday if
<span class="lineNum">    1222 </span>            :      * we're pushing down sufficiently large plan trees.  For now, do it the
<span class="lineNum">    1223 </span>            :      * slow, dumb way.
<span class="lineNum">    1224 </span>            :      */
<span class="lineNum">    1225 </span><span class="lineCov">       2398 :     for (i = 0; i &lt; instrumentation-&gt;num_plan_nodes; ++i)</span>
<span class="lineNum">    1226 </span><span class="lineCov">       2398 :         if (instrumentation-&gt;plan_node_id[i] == plan_node_id)</span>
<span class="lineNum">    1227 </span><span class="lineCov">        734 :             break;</span>
<span class="lineNum">    1228 </span><span class="lineCov">        734 :     if (i &gt;= instrumentation-&gt;num_plan_nodes)</span>
<span class="lineNum">    1229 </span><span class="lineNoCov">          0 :         elog(ERROR, &quot;plan node %d not found&quot;, plan_node_id);</span>
<span class="lineNum">    1230 </span>            : 
<span class="lineNum">    1231 </span>            :     /*
<span class="lineNum">    1232 </span>            :      * Add our statistics to the per-node, per-worker totals.  It's possible
<span class="lineNum">    1233 </span>            :      * that this could happen more than once if we relaunched workers.
<span class="lineNum">    1234 </span>            :      */
<span class="lineNum">    1235 </span><span class="lineCov">        734 :     instrument = GetInstrumentationArray(instrumentation);</span>
<span class="lineNum">    1236 </span><span class="lineCov">        734 :     instrument += i * instrumentation-&gt;num_workers;</span>
<span class="lineNum">    1237 </span><span class="lineCov">        734 :     Assert(IsParallelWorker());</span>
<span class="lineNum">    1238 </span><span class="lineCov">        734 :     Assert(ParallelWorkerNumber &lt; instrumentation-&gt;num_workers);</span>
<span class="lineNum">    1239 </span><span class="lineCov">        734 :     InstrAggNode(&amp;instrument[ParallelWorkerNumber], planstate-&gt;instrument);</span>
<span class="lineNum">    1240 </span>            : 
<span class="lineNum">    1241 </span><span class="lineCov">        734 :     return planstate_tree_walker(planstate, ExecParallelReportInstrumentation,</span>
<span class="lineNum">    1242 </span>            :                                  instrumentation);
<span class="lineNum">    1243 </span>            : }
<span class="lineNum">    1244 </span>            : 
<span class="lineNum">    1245 </span>            : /*
<span class="lineNum">    1246 </span>            :  * Initialize the PlanState and its descendants with the information
<span class="lineNum">    1247 </span>            :  * retrieved from shared memory.  This has to be done once the PlanState
<span class="lineNum">    1248 </span>            :  * is allocated and initialized by executor; that is, after ExecutorStart().
<a name="1249"><span class="lineNum">    1249 </span>            :  */</a>
<span class="lineNum">    1250 </span>            : static bool
<span class="lineNum">    1251 </span><span class="lineCov">       2338 : ExecParallelInitializeWorker(PlanState *planstate, ParallelWorkerContext *pwcxt)</span>
<span class="lineNum">    1252 </span>            : {
<span class="lineNum">    1253 </span><span class="lineCov">       2338 :     if (planstate == NULL)</span>
<span class="lineNum">    1254 </span><span class="lineNoCov">          0 :         return false;</span>
<span class="lineNum">    1255 </span>            : 
<span class="lineNum">    1256 </span><span class="lineCov">       2338 :     switch (nodeTag(planstate))</span>
<span class="lineNum">    1257 </span>            :     {
<span class="lineNum">    1258 </span>            :         case T_SeqScanState:
<span class="lineNum">    1259 </span><span class="lineCov">        928 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">    1260 </span><span class="lineCov">        732 :                 ExecSeqScanInitializeWorker((SeqScanState *) planstate, pwcxt);</span>
<span class="lineNum">    1261 </span><span class="lineCov">        928 :             break;</span>
<span class="lineNum">    1262 </span>            :         case T_IndexScanState:
<span class="lineNum">    1263 </span><span class="lineCov">        124 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">    1264 </span><span class="lineCov">         32 :                 ExecIndexScanInitializeWorker((IndexScanState *) planstate,</span>
<span class="lineNum">    1265 </span>            :                                               pwcxt);
<span class="lineNum">    1266 </span><span class="lineCov">        124 :             break;</span>
<span class="lineNum">    1267 </span>            :         case T_IndexOnlyScanState:
<span class="lineNum">    1268 </span><span class="lineCov">         72 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">    1269 </span><span class="lineCov">         64 :                 ExecIndexOnlyScanInitializeWorker((IndexOnlyScanState *) planstate,</span>
<span class="lineNum">    1270 </span>            :                                                   pwcxt);
<span class="lineNum">    1271 </span><span class="lineCov">         72 :             break;</span>
<span class="lineNum">    1272 </span>            :         case T_ForeignScanState:
<span class="lineNum">    1273 </span><span class="lineNoCov">          0 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">    1274 </span><span class="lineNoCov">          0 :                 ExecForeignScanInitializeWorker((ForeignScanState *) planstate,</span>
<span class="lineNum">    1275 </span>            :                                                 pwcxt);
<span class="lineNum">    1276 </span><span class="lineNoCov">          0 :             break;</span>
<span class="lineNum">    1277 </span>            :         case T_AppendState:
<span class="lineNum">    1278 </span><span class="lineCov">         94 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">    1279 </span><span class="lineCov">         74 :                 ExecAppendInitializeWorker((AppendState *) planstate, pwcxt);</span>
<span class="lineNum">    1280 </span><span class="lineCov">         94 :             break;</span>
<span class="lineNum">    1281 </span>            :         case T_CustomScanState:
<span class="lineNum">    1282 </span><span class="lineNoCov">          0 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">    1283 </span><span class="lineNoCov">          0 :                 ExecCustomScanInitializeWorker((CustomScanState *) planstate,</span>
<span class="lineNum">    1284 </span>            :                                                pwcxt);
<span class="lineNum">    1285 </span><span class="lineNoCov">          0 :             break;</span>
<span class="lineNum">    1286 </span>            :         case T_BitmapHeapScanState:
<span class="lineNum">    1287 </span><span class="lineCov">         88 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">    1288 </span><span class="lineCov">         88 :                 ExecBitmapHeapInitializeWorker((BitmapHeapScanState *) planstate,</span>
<span class="lineNum">    1289 </span>            :                                                pwcxt);
<span class="lineNum">    1290 </span><span class="lineCov">         88 :             break;</span>
<span class="lineNum">    1291 </span>            :         case T_HashJoinState:
<span class="lineNum">    1292 </span><span class="lineCov">        170 :             if (planstate-&gt;plan-&gt;parallel_aware)</span>
<span class="lineNum">    1293 </span><span class="lineCov">         90 :                 ExecHashJoinInitializeWorker((HashJoinState *) planstate,</span>
<span class="lineNum">    1294 </span>            :                                              pwcxt);
<span class="lineNum">    1295 </span><span class="lineCov">        170 :             break;</span>
<span class="lineNum">    1296 </span>            :         case T_HashState:
<span class="lineNum">    1297 </span>            :             /* even when not parallel-aware, for EXPLAIN ANALYZE */
<span class="lineNum">    1298 </span><span class="lineCov">        170 :             ExecHashInitializeWorker((HashState *) planstate, pwcxt);</span>
<span class="lineNum">    1299 </span><span class="lineCov">        170 :             break;</span>
<span class="lineNum">    1300 </span>            :         case T_SortState:
<span class="lineNum">    1301 </span>            :             /* even when not parallel-aware, for EXPLAIN ANALYZE */
<span class="lineNum">    1302 </span><span class="lineCov">        130 :             ExecSortInitializeWorker((SortState *) planstate, pwcxt);</span>
<span class="lineNum">    1303 </span><span class="lineCov">        130 :             break;</span>
<span class="lineNum">    1304 </span>            : 
<span class="lineNum">    1305 </span>            :         default:
<span class="lineNum">    1306 </span><span class="lineCov">        562 :             break;</span>
<span class="lineNum">    1307 </span>            :     }
<span class="lineNum">    1308 </span>            : 
<span class="lineNum">    1309 </span><span class="lineCov">       2338 :     return planstate_tree_walker(planstate, ExecParallelInitializeWorker,</span>
<span class="lineNum">    1310 </span>            :                                  pwcxt);
<span class="lineNum">    1311 </span>            : }
<span class="lineNum">    1312 </span>            : 
<span class="lineNum">    1313 </span>            : /*
<span class="lineNum">    1314 </span>            :  * Main entrypoint for parallel query worker processes.
<span class="lineNum">    1315 </span>            :  *
<span class="lineNum">    1316 </span>            :  * We reach this function from ParallelWorkerMain, so the setup necessary to
<span class="lineNum">    1317 </span>            :  * create a sensible parallel environment has already been done;
<span class="lineNum">    1318 </span>            :  * ParallelWorkerMain worries about stuff like the transaction state, combo
<span class="lineNum">    1319 </span>            :  * CID mappings, and GUC values, so we don't need to deal with any of that
<span class="lineNum">    1320 </span>            :  * here.
<span class="lineNum">    1321 </span>            :  *
<span class="lineNum">    1322 </span>            :  * Our job is to deal with concerns specific to the executor.  The parallel
<span class="lineNum">    1323 </span>            :  * group leader will have stored a serialized PlannedStmt, and it's our job
<span class="lineNum">    1324 </span>            :  * to execute that plan and write the resulting tuples to the appropriate
<span class="lineNum">    1325 </span>            :  * tuple queue.  Various bits of supporting information that we need in order
<span class="lineNum">    1326 </span>            :  * to do this are also stored in the dsm_segment and can be accessed through
<span class="lineNum">    1327 </span>            :  * the shm_toc.
<a name="1328"><span class="lineNum">    1328 </span>            :  */</a>
<span class="lineNum">    1329 </span>            : void
<span class="lineNum">    1330 </span><span class="lineCov">        706 : ParallelQueryMain(dsm_segment *seg, shm_toc *toc)</span>
<span class="lineNum">    1331 </span>            : {
<span class="lineNum">    1332 </span>            :     FixedParallelExecutorState *fpes;
<span class="lineNum">    1333 </span>            :     BufferUsage *buffer_usage;
<span class="lineNum">    1334 </span>            :     DestReceiver *receiver;
<span class="lineNum">    1335 </span>            :     QueryDesc  *queryDesc;
<span class="lineNum">    1336 </span>            :     SharedExecutorInstrumentation *instrumentation;
<span class="lineNum">    1337 </span>            :     SharedJitInstrumentation *jit_instrumentation;
<span class="lineNum">    1338 </span><span class="lineCov">        706 :     int         instrument_options = 0;</span>
<span class="lineNum">    1339 </span>            :     void       *area_space;
<span class="lineNum">    1340 </span>            :     dsa_area   *area;
<span class="lineNum">    1341 </span>            :     ParallelWorkerContext pwcxt;
<span class="lineNum">    1342 </span>            : 
<span class="lineNum">    1343 </span>            :     /* Get fixed-size state. */
<span class="lineNum">    1344 </span><span class="lineCov">        706 :     fpes = shm_toc_lookup(toc, PARALLEL_KEY_EXECUTOR_FIXED, false);</span>
<span class="lineNum">    1345 </span>            : 
<span class="lineNum">    1346 </span>            :     /* Set up DestReceiver, SharedExecutorInstrumentation, and QueryDesc. */
<span class="lineNum">    1347 </span><span class="lineCov">        706 :     receiver = ExecParallelGetReceiver(seg, toc);</span>
<span class="lineNum">    1348 </span><span class="lineCov">        706 :     instrumentation = shm_toc_lookup(toc, PARALLEL_KEY_INSTRUMENTATION, true);</span>
<span class="lineNum">    1349 </span><span class="lineCov">        706 :     if (instrumentation != NULL)</span>
<span class="lineNum">    1350 </span><span class="lineCov">        226 :         instrument_options = instrumentation-&gt;instrument_options;</span>
<span class="lineNum">    1351 </span><span class="lineCov">        706 :     jit_instrumentation = shm_toc_lookup(toc, PARALLEL_KEY_JIT_INSTRUMENTATION,</span>
<span class="lineNum">    1352 </span>            :                                          true);
<span class="lineNum">    1353 </span><span class="lineCov">        706 :     queryDesc = ExecParallelGetQueryDesc(toc, receiver, instrument_options);</span>
<span class="lineNum">    1354 </span>            : 
<span class="lineNum">    1355 </span>            :     /* Setting debug_query_string for individual workers */
<span class="lineNum">    1356 </span><span class="lineCov">        706 :     debug_query_string = queryDesc-&gt;sourceText;</span>
<span class="lineNum">    1357 </span>            : 
<span class="lineNum">    1358 </span>            :     /* Report workers' query for monitoring purposes */
<span class="lineNum">    1359 </span><span class="lineCov">        706 :     pgstat_report_activity(STATE_RUNNING, debug_query_string);</span>
<span class="lineNum">    1360 </span>            : 
<span class="lineNum">    1361 </span>            :     /* Attach to the dynamic shared memory area. */
<span class="lineNum">    1362 </span><span class="lineCov">        706 :     area_space = shm_toc_lookup(toc, PARALLEL_KEY_DSA, false);</span>
<span class="lineNum">    1363 </span><span class="lineCov">        706 :     area = dsa_attach_in_place(area_space, seg);</span>
<span class="lineNum">    1364 </span>            : 
<span class="lineNum">    1365 </span>            :     /* Start up the executor */
<span class="lineNum">    1366 </span><span class="lineCov">        706 :     queryDesc-&gt;plannedstmt-&gt;jitFlags = fpes-&gt;jit_flags;</span>
<span class="lineNum">    1367 </span><span class="lineCov">        706 :     ExecutorStart(queryDesc, fpes-&gt;eflags);</span>
<span class="lineNum">    1368 </span>            : 
<span class="lineNum">    1369 </span>            :     /* Special executor initialization steps for parallel workers */
<span class="lineNum">    1370 </span><span class="lineCov">        706 :     queryDesc-&gt;planstate-&gt;state-&gt;es_query_dsa = area;</span>
<span class="lineNum">    1371 </span><span class="lineCov">        706 :     if (DsaPointerIsValid(fpes-&gt;param_exec))</span>
<span class="lineNum">    1372 </span>            :     {
<span class="lineNum">    1373 </span>            :         char       *paramexec_space;
<span class="lineNum">    1374 </span>            : 
<span class="lineNum">    1375 </span><span class="lineCov">         12 :         paramexec_space = dsa_get_address(area, fpes-&gt;param_exec);</span>
<span class="lineNum">    1376 </span><span class="lineCov">         12 :         RestoreParamExecParams(paramexec_space, queryDesc-&gt;estate);</span>
<span class="lineNum">    1377 </span>            : 
<span class="lineNum">    1378 </span>            :     }
<span class="lineNum">    1379 </span><span class="lineCov">        706 :     pwcxt.toc = toc;</span>
<span class="lineNum">    1380 </span><span class="lineCov">        706 :     pwcxt.seg = seg;</span>
<span class="lineNum">    1381 </span><span class="lineCov">        706 :     ExecParallelInitializeWorker(queryDesc-&gt;planstate, &amp;pwcxt);</span>
<span class="lineNum">    1382 </span>            : 
<span class="lineNum">    1383 </span>            :     /* Pass down any tuple bound */
<span class="lineNum">    1384 </span><span class="lineCov">        706 :     ExecSetTupleBound(fpes-&gt;tuples_needed, queryDesc-&gt;planstate);</span>
<span class="lineNum">    1385 </span>            : 
<span class="lineNum">    1386 </span>            :     /*
<span class="lineNum">    1387 </span>            :      * Prepare to track buffer usage during query execution.
<span class="lineNum">    1388 </span>            :      *
<span class="lineNum">    1389 </span>            :      * We do this after starting up the executor to match what happens in the
<span class="lineNum">    1390 </span>            :      * leader, which also doesn't count buffer accesses that occur during
<span class="lineNum">    1391 </span>            :      * executor startup.
<span class="lineNum">    1392 </span>            :      */
<span class="lineNum">    1393 </span><span class="lineCov">        706 :     InstrStartParallelQuery();</span>
<span class="lineNum">    1394 </span>            : 
<span class="lineNum">    1395 </span>            :     /*
<span class="lineNum">    1396 </span>            :      * Run the plan.  If we specified a tuple bound, be careful not to demand
<span class="lineNum">    1397 </span>            :      * more tuples than that.
<span class="lineNum">    1398 </span>            :      */
<span class="lineNum">    1399 </span><span class="lineCov">        706 :     ExecutorRun(queryDesc,</span>
<span class="lineNum">    1400 </span>            :                 ForwardScanDirection,
<span class="lineNum">    1401 </span><span class="lineCov">        706 :                 fpes-&gt;tuples_needed &lt; 0 ? (int64) 0 : fpes-&gt;tuples_needed,</span>
<span class="lineNum">    1402 </span>            :                 true);
<span class="lineNum">    1403 </span>            : 
<span class="lineNum">    1404 </span>            :     /* Shut down the executor */
<span class="lineNum">    1405 </span><span class="lineCov">        704 :     ExecutorFinish(queryDesc);</span>
<span class="lineNum">    1406 </span>            : 
<span class="lineNum">    1407 </span>            :     /* Report buffer usage during parallel execution. */
<span class="lineNum">    1408 </span><span class="lineCov">        704 :     buffer_usage = shm_toc_lookup(toc, PARALLEL_KEY_BUFFER_USAGE, false);</span>
<span class="lineNum">    1409 </span><span class="lineCov">        704 :     InstrEndParallelQuery(&amp;buffer_usage[ParallelWorkerNumber]);</span>
<span class="lineNum">    1410 </span>            : 
<span class="lineNum">    1411 </span>            :     /* Report instrumentation data if any instrumentation options are set. */
<span class="lineNum">    1412 </span><span class="lineCov">        704 :     if (instrumentation != NULL)</span>
<span class="lineNum">    1413 </span><span class="lineCov">        226 :         ExecParallelReportInstrumentation(queryDesc-&gt;planstate,</span>
<span class="lineNum">    1414 </span>            :                                           instrumentation);
<span class="lineNum">    1415 </span>            : 
<span class="lineNum">    1416 </span>            :     /* Report JIT instrumentation data if any */
<span class="lineNum">    1417 </span><span class="lineCov">        704 :     if (queryDesc-&gt;estate-&gt;es_jit &amp;&amp; jit_instrumentation != NULL)</span>
<span class="lineNum">    1418 </span>            :     {
<span class="lineNum">    1419 </span><span class="lineNoCov">          0 :         Assert(ParallelWorkerNumber &lt; jit_instrumentation-&gt;num_workers);</span>
<span class="lineNum">    1420 </span><span class="lineNoCov">          0 :         jit_instrumentation-&gt;jit_instr[ParallelWorkerNumber] =</span>
<span class="lineNum">    1421 </span><span class="lineNoCov">          0 :             queryDesc-&gt;estate-&gt;es_jit-&gt;instr;</span>
<span class="lineNum">    1422 </span>            :     }
<span class="lineNum">    1423 </span>            : 
<span class="lineNum">    1424 </span>            :     /* Must do this after capturing instrumentation. */
<span class="lineNum">    1425 </span><span class="lineCov">        704 :     ExecutorEnd(queryDesc);</span>
<span class="lineNum">    1426 </span>            : 
<span class="lineNum">    1427 </span>            :     /* Cleanup. */
<span class="lineNum">    1428 </span><span class="lineCov">        704 :     dsa_detach(area);</span>
<span class="lineNum">    1429 </span><span class="lineCov">        704 :     FreeQueryDesc(queryDesc);</span>
<span class="lineNum">    1430 </span><span class="lineCov">        704 :     receiver-&gt;rDestroy(receiver);</span>
<span class="lineNum">    1431 </span><span class="lineCov">        704 : }</span>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.13</a></td></tr>
  </table>
  <br>

</body>
</html>
